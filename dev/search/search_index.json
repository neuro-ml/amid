{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":"<p>Awesome Medical Imaging Datasets (AMID) - a curated list of medical imaging datasets with unified interfaces</p>"},{"location":"#getting-started","title":"Getting started","text":"<p>Just import a dataset and start using it!</p> <p>Note that for some datasets you must manually download the raw files first.</p> <pre><code>from amid.verse import VerSe\nds = VerSe()\n# get the available ids\nprint(len(ds.ids))\ni = ds.ids[0]\n# use the available methods:\n#   load the image and vertebrae masks\nx, y = ds.image(i), ds.masks(i)\nprint(ds.split(i), ds.patient(i))\n# or get a namedTuple-like object:\nentry = ds(i)\nx, y = entry.image, entry.masks\nprint(entry.split, entry.patient)\n</code></pre>"},{"location":"#install","title":"Install","text":"<p>Just get it from PyPi:</p> <pre><code>pip install amid\n</code></pre> <p>Or if you want to use version control features:</p> <pre><code>git clone https://github.com/neuro-ml/amid.git\ncd amid &amp;&amp; pip install -e .\n</code></pre>"},{"location":"CONTRIBUTING/","title":"Contribution Guidelines","text":""},{"location":"CONTRIBUTING/#preparing-the-environment","title":"Preparing the environment","text":"<p>1. First, set up a cache storage. Create the file <code>~/.config/amid/.bev.yml</code> with the following content:</p> <pre><code>main:\nstorage: /path/to/storage\ncache: /path/to/cache\n</code></pre> <p>where <code>/path/to/storage</code> and <code>/path/to/cache</code> are some paths in your filesystem.</p> <p>2. Run</p> <pre><code>amid init\n</code></pre> <p>The full command could look something like this:</p> <pre><code>mkdir -p ~/.config/amid\ncat &gt;~/.config/amid/.bev.yml &lt;&lt;EOL\nmain:\n  storage: /mount/data/storage\n  cache: /mount/data/cache\nEOL\namid init\n</code></pre>"},{"location":"CONTRIBUTING/#adding-a-new-dataset","title":"Adding a new dataset","text":"<p>We will be using LiTS as an example.</p> <p>1. Download the raw data to a separate folder in your filesystem</p> <p>2. (Optionally) create a new branch for the dataset:</p> <pre><code>git checkout lits\n</code></pre> <p>3. Create a class that loads the raw data. LiTSBase is a good example. Note how each field is implemented as a separate function.</p> <p>There are no strict rules regarding the dataset fields, but try to keep the output \"as raw as possible\", i.e., do not apply heavy processing that modifies the data irreversibly.</p> <p>Rule of thumb:</p> <p>The dataset should be written in such a way, that making a submission to a contest would work out of the box.</p> <p>Note</p> <p>In case of DICOM files, make sure to transpose the first 2 image axes.  This way, the image axes will be consistent with the potential contour coordinates.</p> <p>Tip</p> <p>If some value is missing for a given id, it is preferable to return <code>None</code> instead of raising an exception.</p> <p>Tip</p> <p>The dataset must have a docstring which describes it and provides a link to the original data.</p> <p>Tip</p> <p>If the raw data contains a table with metadata, it is preferable to split the metadata columns into separate fields.</p> <p>4. Register the dataset like so:</p> <pre><code>from amid.internals import normalize\nLiTS = normalize(\nLiTSBase, 'LiTS', 'lits',\n...,\n)\n</code></pre> <p>where the first 3 arguments are</p> <ul> <li>the raw dataset</li> <li>the final dataset name</li> <li>a short name for the dataset (mostly used for various files generation)</li> </ul> <p>and <code>...</code> stands for the following arguments:</p> <ul> <li><code>modality</code> \u2014 the images' modality/modalities, e.g., CT, MRI</li> <li><code>body_region</code> \u2014 the anatomical regions present in the dataset, e.g., Head, Thorax, Abdomen</li> <li><code>license</code> \u2014 the dataset's license, if any</li> <li><code>link</code> \u2014 the link to the original data</li> <li><code>raw_data_size</code> \u2014 the total size, required for the raw data, e.g., 10G, 500M</li> <li><code>task</code> \u2014 the dataset's downstream task if any.     E.g., Supervised Learning, Domain Adaptation, Self-supervised Learning, Tumor Segmentation, etc.</li> </ul> <p>5. Make sure all the methods are working as expected:</p> <pre><code>from amid.lits import LiTS\ndataset = LiTS(root=\"/datasets/LiTS\")\nprint(len(dataset.ids))\nid_ = dataset.ids[0]\nprint(dataset.image(id_).shape)\n</code></pre> <p>6. Populate the dataset:</p> <pre><code>amid populate LiTS /shared/data/LiTS\n</code></pre> <p>Tip</p> <p>Use the option <code>--n-jobs</code> to speed up the process.</p> <p>Tip</p> <p>Use the option <code>--help</code> for a more detailed information on this command.</p> <p>7. If there is no error, the file <code>amid/data/lits.hash</code> will appear (the name depends on <code>short_name</code> given to <code>normalize</code>).</p> <p>8. Check the codestyle using the <code>lint.sh</code> script in the repository's root and make changes if flake8 is not happy:</p> <pre><code>pip install -r lint-requirements.txt # only for the first time\n./lint.sh\n</code></pre> <p>9. Commit all the files you added, including the <code>*.hash</code> one.</p>"},{"location":"datasets-api/","title":"Datasets API","text":""},{"location":"datasets-api/#amid.amos.dataset.AMOS","title":"<code>amid.amos.dataset.AMOS</code>","text":"<p>AMOS provides 500 CT and 100 MRI scans collected from multi-center, multi-vendor, multi-modality, multi-phase, multi-disease patients, each with voxel-level annotations of 15 abdominal organs, providing challenging examples and test-bed for studying robust segmentation algorithms under diverse targets and scenarios. [1]</p> <p>Parameters:</p> Name Type Description Default <code>root</code> <code>(str, Path)</code> <p>Absolute path to the root containing the downloaded archive and meta. If not provided, the cache is assumed to be already populated.</p> required"},{"location":"datasets-api/#amid.amos.dataset.AMOS--notes","title":"Notes","text":"<p>Download link: https://zenodo.org/record/7262581/files/amos22.zip</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Download the archive and meta to any folder and pass the path to the constructor:\n&gt;&gt;&gt; ds = AMOS(root='/path/to/the/downloaded/files')\n&gt;&gt;&gt; print(len(ds.ids))\n# 961\n&gt;&gt;&gt; print(ds.image(ds.ids[0]).shape)\n# (768, 768, 90)\n&gt;&gt;&gt; print(ds.mask(ds.ids[26]).shape)\n# (512, 512, 124)\n</code></pre>"},{"location":"datasets-api/#amid.amos.dataset.AMOS--references","title":"References","text":"<p>.. [1] JI YUANFENG. (2022). Amos: A large-scale abdominal multi-organ benchmark for versatile medical image segmentation [Data set]. Zenodo. https://doi.org/10.5281/zenodo.7262581</p>"},{"location":"datasets-api/#amid.amos.dataset.AMOS.birth_date","title":"<code>birth_date(id: str)</code>","text":""},{"location":"datasets-api/#amid.amos.dataset.AMOS.sex","title":"<code>sex(id: str)</code>","text":""},{"location":"datasets-api/#amid.amos.dataset.AMOS.age","title":"<code>age(id: str)</code>","text":""},{"location":"datasets-api/#amid.amos.dataset.AMOS.manufacturer_model","title":"<code>manufacturer_model(id: str)</code>","text":""},{"location":"datasets-api/#amid.amos.dataset.AMOS.manufacturer","title":"<code>manufacturer(id: str)</code>","text":""},{"location":"datasets-api/#amid.amos.dataset.AMOS.acquisition_date","title":"<code>acquisition_date(id: str)</code>","text":""},{"location":"datasets-api/#amid.amos.dataset.AMOS.site","title":"<code>site(id: str)</code>","text":""},{"location":"datasets-api/#amid.amos.dataset.AMOS.ids","title":"<code>ids()</code>","text":""},{"location":"datasets-api/#amid.amos.dataset.AMOS.image","title":"<code>image(id: str)</code>","text":""},{"location":"datasets-api/#amid.amos.dataset.AMOS.affine","title":"<code>affine(id: str)</code>","text":"<p>The 4x4 matrix that gives the image's spatial orientation</p>"},{"location":"datasets-api/#amid.amos.dataset.AMOS.mask","title":"<code>mask(id: str)</code>","text":""},{"location":"datasets-api/#amid.bimcv.BIMCVCovid19","title":"<code>amid.bimcv.BIMCVCovid19</code>","text":"<p>BIMCV COVID-19 Dataset, CT-images only It includes BIMCV COVID-19 positive partition (https://arxiv.org/pdf/2006.01174.pdf) and negative partion (https://ieee-dataport.org/open-access/bimcv-covid-19-large-annotated-dataset-rx-and-ct-images-covid-19-patients-0)</p> <p>PCR tests are not used</p> <p>GitHub page: https://github.com/BIMCV-CSUSP/BIMCV-COVID-19</p> <p>Parameters:</p> Name Type Description Default <code>root</code> <code>(str, Path)</code> <p>path to the folder containing the downloaded and parsed data.</p> required"},{"location":"datasets-api/#amid.bimcv.BIMCVCovid19--notes","title":"Notes","text":"<p>Dataset has 2 partitions: bimcv-covid19-positive and bimcv-covid19-positive Each partition is spread over the 81 different tgz archives. The archives includes metadata about subject, sessions, and labels. Also there are some tgz archives for nifty images in nii.gz format</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Place the downloaded archives in any folder and pass the path to the constructor:\n&gt;&gt;&gt; ds = BIMCVCovid19(root='/path/to/downloaded/data/folder/')\n&gt;&gt;&gt; print(len(ds.ids))\n# 201\n&gt;&gt;&gt; print(ds.image(ds.ids[0]).shape)\n# (512, 512, 163)\n&gt;&gt;&gt; print(ds.is_positive(ds.ids[0]))\n# True\n&gt;&gt;&gt; print(ds.subject_info[80])\n# {'modality_dicom': \"['CT']\",\n#  'body_parts': \"[['chest']]\",\n#  'age': '[80]',\n#  'gender': 'M'}\n</code></pre>"},{"location":"datasets-api/#amid.bimcv.BIMCVCovid19--references","title":"References","text":"<p>.. [1] Maria De La Iglesia Vay\u00e1, Jose Manuel Saborit, Joaquim Angel Montell, Antonio Pertusa, Aurelia         Bustos, Miguel Cazorla, Joaquin Galant, Xavier Barber, Domingo Orozco-Beltr\u00e1n, Francisco         Garcia, Marisa Caparr\u00f3s, Germ\u00e1n Gonz\u00e1lez, and Jose Mar\u00eda Salinas. BIMCV COVID-19+: a         large annotated dataset of RX and CT images from COVID-19 patients. arXiv:2006.01174, 2020. .. [2] Maria de la Iglesia Vay\u00e1, Jose Manuel Saborit-Torres, Joaquim Angel Montell Serrano,         Elena Oliver-Garcia, Antonio Pertusa, Aurelia Bustos, Miguel Cazorla, Joaquin Galant,         Xavier Barber, Domingo Orozco-Beltr\u00e1n, Francisco Garc\u00eda-Garc\u00eda, Marisa Caparr\u00f3s, Germ\u00e1n Gonz\u00e1lez,         Jose Mar\u00eda Salinas, 2021. BIMCV COVID-19-: a large annotated dataset of RX and CT images from COVID-19         patients.         Available at: https://dx.doi.org/10.21227/m4j2-ap59.</p>"},{"location":"datasets-api/#amid.bimcv.BIMCVCovid19.ids","title":"<code>ids()</code>","text":""},{"location":"datasets-api/#amid.bimcv.BIMCVCovid19.session_id","title":"<code>session_id(id: str)</code>","text":""},{"location":"datasets-api/#amid.bimcv.BIMCVCovid19.subject_id","title":"<code>subject_id(id: str)</code>","text":""},{"location":"datasets-api/#amid.bimcv.BIMCVCovid19.is_positive","title":"<code>is_positive(id: str)</code>","text":""},{"location":"datasets-api/#amid.bimcv.BIMCVCovid19.image","title":"<code>image(id: str)</code>","text":""},{"location":"datasets-api/#amid.bimcv.BIMCVCovid19.affine","title":"<code>affine(id: str)</code>","text":""},{"location":"datasets-api/#amid.bimcv.BIMCVCovid19.tags","title":"<code>tags(id: str) -&gt; dict</code>","text":"<p>dicom tags</p>"},{"location":"datasets-api/#amid.bimcv.BIMCVCovid19.label_info","title":"<code>label_info(id: str) -&gt; dict</code>","text":"<p>labelCUIS, Report, LocalizationsCUIS etc.</p>"},{"location":"datasets-api/#amid.bimcv.BIMCVCovid19.subject_info","title":"<code>subject_info(id: str) -&gt; dict</code>","text":"<p>modality_dicom (=[CT]), body_parts(=[chest]), age, gender</p>"},{"location":"datasets-api/#amid.bimcv.BIMCVCovid19.age","title":"<code>age(id: str) -&gt; int</code>","text":"<p>Minimum of (possibly two) available ages. The maximum difference between max and min age for every patient is 1 year.</p>"},{"location":"datasets-api/#amid.bimcv.BIMCVCovid19.sex","title":"<code>sex(id: str) -&gt; str</code>","text":""},{"location":"datasets-api/#amid.bimcv.BIMCVCovid19.session_info","title":"<code>session_info(id: str) -&gt; dict</code>","text":"<p>study_date,     medical_evaluation</p>"},{"location":"datasets-api/#amid.brats2021.BraTS2021","title":"<code>amid.brats2021.BraTS2021</code>","text":"<p>Parameters:</p> Name Type Description Default <code>root</code> <code>(str, Path)</code> <p>path to the folder containing the raw downloaded archives. If not provided, the cache is assumed to be already populated.</p> required <code>version</code> <code>str</code> <p>the data version. Only has effect if the library was installed from a cloned git repository.</p> required"},{"location":"datasets-api/#amid.brats2021.BraTS2021--notes","title":"Notes","text":"<p>Download links: 2021: http://www.braintumorsegmentation.org/</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Place the downloaded archives in any folder and pass the path to the constructor:\n&gt;&gt;&gt; ds = BraTS2021(root='/path/to/archives/root')\n&gt;&gt;&gt; print(len(ds.ids))\n# 5880\n&gt;&gt;&gt; print(ds.image(ds.ids[0]).shape)\n# (240, 240, 155)\n</code></pre>"},{"location":"datasets-api/#amid.brats2021.BraTS2021--references","title":"References","text":""},{"location":"datasets-api/#amid.brats2021.BraTS2021.ids","title":"<code>ids()</code>","text":""},{"location":"datasets-api/#amid.brats2021.BraTS2021.fold","title":"<code>fold(id: str)</code>","text":""},{"location":"datasets-api/#amid.brats2021.BraTS2021.mapping21_17","title":"<code>mapping21_17(id: str) -&gt; pd.DataFrame</code>","text":""},{"location":"datasets-api/#amid.brats2021.BraTS2021.subject_id","title":"<code>subject_id(id: str) -&gt; str</code>","text":""},{"location":"datasets-api/#amid.brats2021.BraTS2021.modality","title":"<code>modality(id: str) -&gt; str</code>","text":""},{"location":"datasets-api/#amid.brats2021.BraTS2021.image","title":"<code>image(id: str)</code>","text":""},{"location":"datasets-api/#amid.brats2021.BraTS2021.mask","title":"<code>mask(id: str)</code>","text":""},{"location":"datasets-api/#amid.brats2021.BraTS2021.spacing","title":"<code>spacing(id: str)</code>","text":"<p>Returns the voxel spacing along axes (x, y, z).</p>"},{"location":"datasets-api/#amid.brats2021.BraTS2021.affine","title":"<code>affine(id: str)</code>","text":"<p>Returns 4x4 matrix that gives the image's spatial orientation.</p>"},{"location":"datasets-api/#amid.cc359.dataset.CC359","title":"<code>amid.cc359.dataset.CC359</code>","text":"<p>A (C)algary-(C)ampinas public brain MR dataset with (359) volumetric images [1]_.</p> <p>There are three segmentation tasks on this dataset: (i) brain, (ii) hippocampus, and (iii) White-Matter (WM), Gray-Matter (WM), and Cerebrospinal Fluid (CSF) segmentation.</p> <p>Parameters:</p> Name Type Description Default <code>root</code> <code>(str, Path)</code> <p>path to the folder containing the raw downloaded archives. If not provided, the cache is assumed to be already populated.</p> required <code>version</code> <code>str</code> <p>the data version. Only has effect if the library was installed from a cloned git repository.</p> required"},{"location":"datasets-api/#amid.cc359.dataset.CC359--notes","title":"Notes","text":"<p>homepage (upd): https://sites.google.com/view/calgary-campinas-dataset/home homepage (old): https://miclab.fee.unicamp.br/calgary-campinas-359-updated-05092017</p> <p>To obtain MR images and brain and hippocampus segmentation masks, please, follow the instructions at the download platform: https://portal.conp.ca/dataset?id=projects/calgary-campinas.</p> <p>Via <code>datalad</code> lib you need to download three zip archives:     - <code>Original.zip</code> (the original MR images)     - <code>hippocampus_staple.zip</code> (Silver-standard hippocampus masks generated using STAPLE)     - <code>Silver-standard-machine-learning.zip</code> (Silver-standard brain masks generated using a machine learning method)</p> <p>To the current date, WM, GM, and CSF mask could be downloaded only from the google drive: https://drive.google.com/drive/u/0/folders/0BxLb0NB2MjVZNm9JY1pWNFp6WTA?resourcekey=0-2sXMr8q-n2Nn6iY3PbBAdA.</p> <p>Here you need to manually download a folder (from the google drive root above) <code>CC359/Reconstructed/CC359/WM-GM-CSF/</code></p> <p>So the root folder to pass to this dataset class should contain four objects:     - three zip archives (<code>Original.zip</code>, <code>hippocampus_staple.zip</code>, and <code>Silver-standard-machine-learning.zip</code>)     - one folder <code>WM-GM-CSF</code> with the original structure:         &lt;...&gt;/WM-GM-CSF/CC0319_ge_3_45_M.nii.gz         &lt;...&gt;/WM-GM-CSF/CC0324_ge_3_56_M.nii.gz         ...</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Place the downloaded archives in any folder and pass the path to the constructor:\n&gt;&gt;&gt; cc359 = CC359(root='/path/to/downloaded/data/folder/')\n&gt;&gt;&gt; print(len(cc359.ids))\n# 359\n&gt;&gt;&gt; print(cc359.image(cc359.ids[0]).shape)\n# (171, 256, 256)\n&gt;&gt;&gt; print(cc359.wm_gm_csf(cc359.ids[80]).shape)\n# (180, 240, 240)\n</code></pre>"},{"location":"datasets-api/#amid.cc359.dataset.CC359--references","title":"References","text":"<p>.. [1] Souza, Roberto, et al. \"An open, multi-vendor, multi-field-strength brain MR dataset        and analysis of publicly available skull stripping methods agreement.\"        NeuroImage 170 (2018): 482-494.        https://www.sciencedirect.com/science/article/pii/S1053811917306687</p>"},{"location":"datasets-api/#amid.cc359.dataset.CC359.ids","title":"<code>ids()</code>","text":""},{"location":"datasets-api/#amid.cc359.dataset.CC359.vendor","title":"<code>vendor(id: str)</code>","text":""},{"location":"datasets-api/#amid.cc359.dataset.CC359.field","title":"<code>field(id: str)</code>","text":""},{"location":"datasets-api/#amid.cc359.dataset.CC359.age","title":"<code>age(id: str)</code>","text":""},{"location":"datasets-api/#amid.cc359.dataset.CC359.sex","title":"<code>sex(id: str)</code>","text":""},{"location":"datasets-api/#amid.cc359.dataset.CC359.image","title":"<code>image(id: str)</code>","text":""},{"location":"datasets-api/#amid.cc359.dataset.CC359.affine","title":"<code>affine(id: str)</code>","text":"<p>The 4x4 matrix that gives the image's spatial orientation.</p>"},{"location":"datasets-api/#amid.cc359.dataset.CC359.voxel_spacing","title":"<code>voxel_spacing(id: str)</code>","text":""},{"location":"datasets-api/#amid.cc359.dataset.CC359.spacing","title":"<code>spacing(id: str)</code>","text":"<p>Returns voxel spacing along axes (x, y, z).</p>"},{"location":"datasets-api/#amid.cc359.dataset.CC359.brain","title":"<code>brain(id: str)</code>","text":""},{"location":"datasets-api/#amid.cc359.dataset.CC359.hippocampus","title":"<code>hippocampus(id: str)</code>","text":""},{"location":"datasets-api/#amid.cc359.dataset.CC359.wm_gm_csf","title":"<code>wm_gm_csf(id: str)</code>","text":""},{"location":"datasets-api/#amid.cl_detection.CLDetection2023","title":"<code>amid.cl_detection.CLDetection2023</code>","text":"<p>The data for the \"Cephalometric Landmark Detection in Lateral X-ray Images\" Challenge, held with the MICCAI-2023 conference.</p>"},{"location":"datasets-api/#amid.cl_detection.CLDetection2023--notes","title":"Notes","text":"<p>The data can only be obtained by contacting the organizers by email. See the challenge home page for details.</p> <p>Parameters:</p> Name Type Description Default <code>root</code> <code>(str, Path)</code> <p>path to the folder containing the raw downloaded and unarchived data. If not provided, the cache is assumed to be already populated.</p> required <code>version</code> <code>str</code> <p>the data version. Only has effect if the library was installed from a cloned git repository.</p> required <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Place the downloaded archives in any folder and pass the path to the constructor:\n&gt;&gt;&gt; ds = CLDetection2023(root='/path/to/data/root/folder')\n&gt;&gt;&gt; print(len(ds.ids))\n# 400\n&gt;&gt;&gt; print(ds.image(ds.ids[0]).shape)\n# (2400, 1935)\n</code></pre>"},{"location":"datasets-api/#amid.cl_detection.CLDetection2023.ids","title":"<code>ids()</code>","text":""},{"location":"datasets-api/#amid.cl_detection.CLDetection2023.image","title":"<code>image(id: str)</code>","text":""},{"location":"datasets-api/#amid.cl_detection.CLDetection2023.points","title":"<code>points(id: str)</code>","text":""},{"location":"datasets-api/#amid.cl_detection.CLDetection2023.spacing","title":"<code>spacing(id: str)</code>","text":""},{"location":"datasets-api/#amid.crlm.CRLM","title":"<code>amid.crlm.CRLM</code>","text":"<p>Parameters:</p> Name Type Description Default <code>root</code> <code>(str, Path)</code> <p>path to the folder containing the raw downloaded archives. If not provided, the cache is assumed to be already populated.</p> required <code>version</code> <code>str</code> <p>the data version. Only has effect if the library was installed from a cloned git repository.</p> required"},{"location":"datasets-api/#amid.crlm.CRLM--notes","title":"Notes","text":"<p>Download links: https://wiki.cancerimagingarchive.net/pages/viewpage.action?pageId=89096268#89096268b2cc35fce0664a2b875b5ec675ba9446</p> <p>This collection consists of DICOM images and DICOM Segmentation Objects (DSOs) for 197 patients with Colorectal Liver Metastases (CRLM). Comprised of Original DICOM CTs and Segmentations for each subject. The segmentations include 'Liver', 'Liver_Remnant' (liver that will remain after surgery based on a preoperative CT plan), 'Hepatic' and 'Portal' veins, and 'Tumor_x', where 'x' denotes the various tumor occurrences in the case</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Place the downloaded archives in any folder and pass the path to the constructor:\n&gt;&gt;&gt; ds = CRLM(root='/path/to/archives/root')\n&gt;&gt;&gt; print(len(ds.ids))\n# 197\n&gt;&gt;&gt; print(ds.image(ds.ids[0]).shape)\n# (512, 512, 52)\n</code></pre>"},{"location":"datasets-api/#amid.crlm.CRLM--references","title":"References","text":""},{"location":"datasets-api/#amid.crlm.CRLM.ids","title":"<code>ids()</code>","text":""},{"location":"datasets-api/#amid.crlm.CRLM.image","title":"<code>image(id: str)</code>","text":""},{"location":"datasets-api/#amid.crlm.CRLM.mask","title":"<code>mask(id: str) -&gt; Dict[str, np.ndarray]</code>","text":"<p>Returns dict: {'liver': ..., 'hepatic': ..., 'tumor_x': ...}</p>"},{"location":"datasets-api/#amid.crlm.CRLM.spacing","title":"<code>spacing(id: str)</code>","text":"<p>Returns the voxel spacing along axes (x, y, z).</p>"},{"location":"datasets-api/#amid.crlm.CRLM.slice_locations","title":"<code>slice_locations(id: str)</code>","text":""},{"location":"datasets-api/#amid.crlm.CRLM.affine","title":"<code>affine(id: str)</code>","text":"<p>Returns 4x4 matrix that gives the image's spatial orientation.</p>"},{"location":"datasets-api/#amid.ct_ich.CT_ICH","title":"<code>amid.ct_ich.CT_ICH</code>","text":"<p>(C)omputed (T)omography Images for (I)ntracranial (H)emorrhage Detection and (S)egmentation.</p> <p>This dataset contains 75 head CT scans including 36 scans for patients diagnosed with intracranial hemorrhage with the following types: Intraventricular, Intraparenchymal, Subarachnoid, Epidural and Subdural.</p> <p>Parameters:</p> Name Type Description Default <code>root</code> <code>(str, Path)</code> <p>path to the folder containing the raw downloaded archives. If not provided, the cache is assumed to be already populated.</p> required <code>version</code> <code>str</code> <p>the data version. Only has effect if the library was installed from a cloned git repository.</p> required"},{"location":"datasets-api/#amid.ct_ich.CT_ICH--notes","title":"Notes","text":"<p>Data can be downloaded here: https://physionet.org/content/ct-ich/1.3.1/. Then, the folder with raw downloaded data should contain folders <code>ct_scans</code> and <code>masks</code> along with other files.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Place the downloaded archives in any folder and pass the path to the constructor:\n&gt;&gt;&gt; ds = CT_ICH(root='/path/to/downloaded/data/folder/')\n&gt;&gt;&gt; print(len(ds.ids))\n# 75\n&gt;&gt;&gt; print(ds.image(ds.ids[0]).shape)\n# (512, 512, 39)\n&gt;&gt;&gt; print(ds.mask(ds.ids[0]).shape)\n# (512, 512, 39)\n</code></pre>"},{"location":"datasets-api/#amid.ct_ich.CT_ICH.ids","title":"<code>ids()</code>","text":""},{"location":"datasets-api/#amid.ct_ich.CT_ICH.image","title":"<code>image(id: str)</code>","text":""},{"location":"datasets-api/#amid.ct_ich.CT_ICH.mask","title":"<code>mask(id: str)</code>","text":""},{"location":"datasets-api/#amid.ct_ich.CT_ICH.affine","title":"<code>affine(id: str)</code>","text":"<p>The 4x4 matrix that gives the image's spatial orientation.</p>"},{"location":"datasets-api/#amid.ct_ich.CT_ICH.voxel_spacing","title":"<code>voxel_spacing(id: str)</code>","text":""},{"location":"datasets-api/#amid.ct_ich.CT_ICH.spacing","title":"<code>spacing(id: str)</code>","text":"<p>Returns voxel spacing along axes (x, y, z).</p>"},{"location":"datasets-api/#amid.ct_ich.CT_ICH.age","title":"<code>age(id: str) -&gt; float</code>","text":""},{"location":"datasets-api/#amid.ct_ich.CT_ICH.sex","title":"<code>sex(id: str) -&gt; str</code>","text":""},{"location":"datasets-api/#amid.ct_ich.CT_ICH.intraventricular_hemorrhage","title":"<code>intraventricular_hemorrhage(id: str)</code>","text":"<p>Returns True if hemorrhage exists and its type is intraventricular.</p>"},{"location":"datasets-api/#amid.ct_ich.CT_ICH.intraparenchymal_hemorrhage","title":"<code>intraparenchymal_hemorrhage(id: str)</code>","text":"<p>Returns True if hemorrhage was diagnosed and its type is intraparenchymal.</p>"},{"location":"datasets-api/#amid.ct_ich.CT_ICH.subarachnoid_hemorrhage","title":"<code>subarachnoid_hemorrhage(id: str)</code>","text":"<p>Returns True if hemorrhage was diagnosed and its type is subarachnoid.</p>"},{"location":"datasets-api/#amid.ct_ich.CT_ICH.epidural_hemorrhage","title":"<code>epidural_hemorrhage(id: str)</code>","text":"<p>Returns True if hemorrhage was diagnosed and its type is epidural.</p>"},{"location":"datasets-api/#amid.ct_ich.CT_ICH.subdural_hemorrhage","title":"<code>subdural_hemorrhage(id: str)</code>","text":"<p>Returns True if hemorrhage was diagnosed and its type is subdural.</p>"},{"location":"datasets-api/#amid.ct_ich.CT_ICH.fracture","title":"<code>fracture(id: str)</code>","text":"<p>Returns True if skull fracture was diagnosed.</p>"},{"location":"datasets-api/#amid.ct_ich.CT_ICH.notes","title":"<code>notes(id: str)</code>","text":"<p>Returns special notes if they exist.</p>"},{"location":"datasets-api/#amid.ct_ich.CT_ICH.hemorrhage_diagnosis_raw_metadata","title":"<code>hemorrhage_diagnosis_raw_metadata(id: str)</code>","text":""},{"location":"datasets-api/#amid.crossmoda.CrossMoDA","title":"<code>amid.crossmoda.CrossMoDA</code>","text":"<p>Parameters:</p> Name Type Description Default <code>root</code> <code>(str, Path)</code> <p>path to the folder containing the raw downloaded archives. If not provided, the cache is assumed to be already populated.</p> required <code>version</code> <code>str</code> <p>the data version. Only has effect if the library was installed from a cloned git repository.</p> required"},{"location":"datasets-api/#amid.crossmoda.CrossMoDA--notes","title":"Notes","text":"<p>Download links: 2021 &amp; 2022: https://zenodo.org/record/6504722#.YsgwnNJByV4</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Place the downloaded archives in any folder and pass the path to the constructor:\n&gt;&gt;&gt; ds = CrossMoDA(root='/path/to/archives/root')\n&gt;&gt;&gt; print(len(ds.ids))\n# 484\n&gt;&gt;&gt; print(ds.image(ds.ids[0]).shape)\n# (512, 512, 214)\n</code></pre>"},{"location":"datasets-api/#amid.crossmoda.CrossMoDA--references","title":"References","text":""},{"location":"datasets-api/#amid.crossmoda.CrossMoDA.ids","title":"<code>ids()</code>","text":""},{"location":"datasets-api/#amid.crossmoda.CrossMoDA.train_source_df","title":"<code>train_source_df(id: str)</code>","text":""},{"location":"datasets-api/#amid.crossmoda.CrossMoDA.image","title":"<code>image(id: str) -&gt; Union[np.ndarray, None]</code>","text":""},{"location":"datasets-api/#amid.crossmoda.CrossMoDA.pixel_spacing","title":"<code>pixel_spacing(id: str)</code>","text":""},{"location":"datasets-api/#amid.crossmoda.CrossMoDA.spacing","title":"<code>spacing(id: str)</code>","text":"<p>Returns pixel spacing along axes (x, y, z)</p>"},{"location":"datasets-api/#amid.crossmoda.CrossMoDA.affine","title":"<code>affine(id: str)</code>","text":"<p>The 4x4 matrix that gives the image's spatial orientation</p>"},{"location":"datasets-api/#amid.crossmoda.CrossMoDA.split","title":"<code>split(id: str) -&gt; str</code>","text":"<p>The split in which this entry is contained: training_source, training_target, validation</p>"},{"location":"datasets-api/#amid.crossmoda.CrossMoDA.year","title":"<code>year(id: str) -&gt; int</code>","text":"<p>The year in which this entry was published: 2021 or 2022</p>"},{"location":"datasets-api/#amid.crossmoda.CrossMoDA.masks","title":"<code>masks(id: str) -&gt; Union[np.ndarray, None]</code>","text":"<p>Combined mask of schwannoma and cochlea (1 and 2 respectively)</p>"},{"location":"datasets-api/#amid.crossmoda.CrossMoDA.koos_grade","title":"<code>koos_grade(id: str)</code>","text":"<p>VS Tumour characteristic according to Koos grading scale: [1..4] or (-1 - post operative)</p>"},{"location":"datasets-api/#amid.deeplesion.DeepLesion","title":"<code>amid.deeplesion.DeepLesion</code>","text":"<p>DeepLesion is composed of 33,688 bookmarked radiology images from 10,825 studies of 4,477 unique patients. For every bookmarked image, a bound- ing box is created to cover the target lesion based on its measured diameters [1].</p> <p>Parameters:</p> Name Type Description Default <code>root</code> <code>(str, Path)</code> <p>path to the folder containing <code>DL_info.csv</code> file and a subfolder <code>Images_nifti</code> with 20094 nii.gz files.</p> required"},{"location":"datasets-api/#amid.deeplesion.DeepLesion--notes","title":"Notes","text":"<p>Dataset is available at https://nihcc.app.box.com/v/DeepLesion</p> <p>To download the data we recommend using a Python script provided by the authors <code>batch_download_zips.py</code>. Once you download the data and unarchive all 56 zip archives, you should run <code>DL_save_nifti.py</code> provided by the authors to convert 2D PNGs into 20094 nii.gz files.</p>"},{"location":"datasets-api/#amid.deeplesion.DeepLesion--example","title":"Example","text":"<p>ds = DeepLesion(root='/path/to/folder') print(len(ds.ids))</p>"},{"location":"datasets-api/#amid.deeplesion.DeepLesion--20094","title":"20094","text":""},{"location":"datasets-api/#amid.deeplesion.DeepLesion--references","title":"References","text":"<p>.. [1] Yan, Ke, Xiaosong Wang, Le Lu, and Ronald M. Summers. \"Deeplesion: Automated deep mining,   categorization and detection of significant radiology image findings using large-scale clinical   lesion annotations.\" arXiv preprint arXiv:1710.01766 (2017).</p>"},{"location":"datasets-api/#amid.deeplesion.DeepLesion.ids","title":"<code>ids()</code>","text":""},{"location":"datasets-api/#amid.deeplesion.DeepLesion.patient_id","title":"<code>patient_id(id: str)</code>","text":""},{"location":"datasets-api/#amid.deeplesion.DeepLesion.study_id","title":"<code>study_id(id: str)</code>","text":""},{"location":"datasets-api/#amid.deeplesion.DeepLesion.series_id","title":"<code>series_id(id: str)</code>","text":""},{"location":"datasets-api/#amid.deeplesion.DeepLesion.sex","title":"<code>sex(id: str)</code>","text":""},{"location":"datasets-api/#amid.deeplesion.DeepLesion.age","title":"<code>age(id: str)</code>","text":"<p>Patient Age might be different for different studies (dataset contains longitudinal records).</p>"},{"location":"datasets-api/#amid.deeplesion.DeepLesion.ct_window","title":"<code>ct_window(id: str)</code>","text":"<p>CT window extracted from DICOMs. Recall, that it is min-max values for windowing, not width-level.</p>"},{"location":"datasets-api/#amid.deeplesion.DeepLesion.affine","title":"<code>affine(id: str)</code>","text":""},{"location":"datasets-api/#amid.deeplesion.DeepLesion.spacing","title":"<code>spacing(id: str)</code>","text":""},{"location":"datasets-api/#amid.deeplesion.DeepLesion.image","title":"<code>image(id: str)</code>","text":"<p>Some 3D volumes are stored as separate subvolumes, e.g. ds.ids[15000] and ds.ids[15001].</p>"},{"location":"datasets-api/#amid.deeplesion.DeepLesion.train_val_test","title":"<code>train_val_test(id: str)</code>","text":"<p>Authors' defined randomly generated patient-level data split, train=1, validation=2, test=3, 70/15/15 ratio.</p>"},{"location":"datasets-api/#amid.deeplesion.DeepLesion.lesion_position","title":"<code>lesion_position(id: str)</code>","text":"<p>Lesion measurements as it appear in DL_info.csv, for details see https://nihcc.app.box.com/v/DeepLesion/file/306056134060 .</p>"},{"location":"datasets-api/#amid.deeplesion.DeepLesion.mask","title":"<code>mask(id: str)</code>","text":"<p>Mask of provided bounding boxes. Recall that bboxes annotation is very coarse, it only covers a single 2D slice.</p>"},{"location":"datasets-api/#amid.egd.EGD","title":"<code>amid.egd.EGD</code>","text":"<p>The Erasmus Glioma Database (EGD): Structural MRI scans, WHO 2016 subtypes, and segmentations of 774 patients with glioma [1]_.</p> <p>Parameters:</p> Name Type Description Default <code>root</code> <code>(str, Path)</code> <p>path to the folder containing the raw downloaded archives. If not provided, the cache is assumed to be already populated.</p> required <code>version</code> <code>str</code> <p>the data version. Only has effect if the library was installed from a cloned git repository.</p> required"},{"location":"datasets-api/#amid.egd.EGD--notes","title":"Notes","text":"<p>The access to the dataset could be requested at XNAT portal [https://xnat.bmia.nl/data/archive/projects/egd].</p> <p>To download the data in the compatible structure we recommend to use egd-downloader script [https://zenodo.org/record/4761089#.YtZpLtJBxhF]. Please, refer to its README for further information.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Place the downloaded archives in any folder and pass the path to the constructor:\n&gt;&gt;&gt; egd = EGD(root='/path/to/downloaded/data/folder/')\n&gt;&gt;&gt; print(len(egd.ids))\n# 774\n&gt;&gt;&gt; print(egd.t1gd(egd.ids[215]).shape)\n# (197, 233, 189)\n&gt;&gt;&gt; print(egd.manufacturer(egd.ids[444]))\n# Philips Medical Systems\n</code></pre>"},{"location":"datasets-api/#amid.egd.EGD--references","title":"References","text":"<p>.. [1] van der Voort, Sebastian R., et al. \"The Erasmus Glioma Database (EGD): Structural MRI scans,        WHO 2016 subtypes, and segmentations of 774 patients with glioma.\"        Data in brief 37 (2021): 107191.        https://www.sciencedirect.com/science/article/pii/S2352340921004753</p>"},{"location":"datasets-api/#amid.egd.EGD.ids","title":"<code>ids()</code>","text":""},{"location":"datasets-api/#amid.egd.EGD.brain_mask","title":"<code>brain_mask(id: str)</code>","text":""},{"location":"datasets-api/#amid.egd.EGD.deface_mask","title":"<code>deface_mask(id: str)</code>","text":""},{"location":"datasets-api/#amid.egd.EGD.modality","title":"<code>modality(id: str)</code>","text":""},{"location":"datasets-api/#amid.egd.EGD.subject_id","title":"<code>subject_id(id: str)</code>","text":""},{"location":"datasets-api/#amid.egd.EGD.affine","title":"<code>affine(id: str)</code>","text":""},{"location":"datasets-api/#amid.egd.EGD.voxel_spacing","title":"<code>voxel_spacing(id: str)</code>","text":""},{"location":"datasets-api/#amid.egd.EGD.spacing","title":"<code>spacing(id: str)</code>","text":""},{"location":"datasets-api/#amid.egd.EGD.image","title":"<code>image(id: str)</code>","text":""},{"location":"datasets-api/#amid.egd.EGD.genetic_and_histological_label_idh","title":"<code>genetic_and_histological_label_idh(id: str)</code>","text":""},{"location":"datasets-api/#amid.egd.EGD.genetic_and_histological_label_1p19q","title":"<code>genetic_and_histological_label_1p19q(id: str)</code>","text":""},{"location":"datasets-api/#amid.egd.EGD.genetic_and_histological_label_grade","title":"<code>genetic_and_histological_label_grade(id: str)</code>","text":""},{"location":"datasets-api/#amid.egd.EGD.age","title":"<code>age(id: str)</code>","text":""},{"location":"datasets-api/#amid.egd.EGD.sex","title":"<code>sex(id: str)</code>","text":""},{"location":"datasets-api/#amid.egd.EGD.observer","title":"<code>observer(id: str)</code>","text":""},{"location":"datasets-api/#amid.egd.EGD.original_scan","title":"<code>original_scan(id: str)</code>","text":""},{"location":"datasets-api/#amid.egd.EGD.manufacturer","title":"<code>manufacturer(id: str)</code>","text":""},{"location":"datasets-api/#amid.egd.EGD.system","title":"<code>system(id: str)</code>","text":""},{"location":"datasets-api/#amid.egd.EGD.field","title":"<code>field(id: str)</code>","text":""},{"location":"datasets-api/#amid.egd.EGD.mask","title":"<code>mask(id: str)</code>","text":""},{"location":"datasets-api/#amid.flare2022.FLARE2022","title":"<code>amid.flare2022.FLARE2022</code>","text":"<p>An abdominal organ segmentation dataset for semi-supervised learning [1]_.</p> <p>The dataset was used at the MICCAI FLARE 2022 challenge.</p> <p>Parameters:</p> Name Type Description Default <code>root</code> <code>(str, Path)</code> <p>path to the folder containing the raw downloaded archives. If not provided, the cache is assumed to be already populated.</p> required"},{"location":"datasets-api/#amid.flare2022.FLARE2022--notes","title":"Notes","text":"<p>Download link: https://flare22.grand-challenge.org/Dataset/</p> <p>The <code>root</code> folder should contain the two downloaded folders, namely: \"Training\" and \"Validation\".</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Place the downloaded folders in any folder and pass the path to the constructor:\n&gt;&gt;&gt; ds = FLARE2022(root='/path/to/downloaded/data/folder/')\n&gt;&gt;&gt; print(len(ds.ids))\n# 2100\n&gt;&gt;&gt; print(ds.image(ds.ids[0]).shape)\n# (512, 512, 110)\n&gt;&gt;&gt; print(ds.mask(ds.ids[25]).shape)\n# (512, 512, 104)\n</code></pre>"},{"location":"datasets-api/#amid.flare2022.FLARE2022--references","title":"References","text":"<p>.. [1] Ma, Jun, et al. \"Fast and Low-GPU-memory abdomen CT organ segmentation: The FLARE challenge.\" Medical Image Analysis 82 (2022): 102616.</p>"},{"location":"datasets-api/#amid.flare2022.FLARE2022.ids","title":"<code>ids()</code>","text":""},{"location":"datasets-api/#amid.flare2022.FLARE2022.image","title":"<code>image(id: str)</code>","text":""},{"location":"datasets-api/#amid.flare2022.FLARE2022.affine","title":"<code>affine(id: str)</code>","text":"<p>The 4x4 matrix that gives the image's spatial orientation</p>"},{"location":"datasets-api/#amid.flare2022.FLARE2022.mask","title":"<code>mask(id: str)</code>","text":""},{"location":"datasets-api/#amid.lidc.dataset.LIDC","title":"<code>amid.lidc.dataset.LIDC</code>","text":"<p>The (L)ung (I)mage (D)atabase (C)onsortium image collection (LIDC-IDRI) [1]_ consists of diagnostic and lung cancer screening thoracic computed tomography (CT) scans with marked-up annotated lesions and lung nodules segmentation task. Scans contains multiple expert annotations.</p> <p>Number of CT scans: 1018.</p> <p>Parameters:</p> Name Type Description Default <code>root</code> <code>(str, Path)</code> <p>path to the folder containing the raw downloaded archives. If not provided, the cache is assumed to be already populated.</p> required <code>version</code> <code>str</code> <p>the data version. Only has effect if the library was installed from a cloned git repository.</p> required"},{"location":"datasets-api/#amid.lidc.dataset.LIDC--notes","title":"Notes","text":"<p>Follow the download instructions at https://wiki.cancerimagingarchive.net/pages/viewpage.action?pageId=1966254.</p> <p>Then, the folder with raw downloaded data should contain folder <code>LIDC-IDRI</code>, which contains folders <code>LIDC-IDRI-*</code>.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Place the downloaded archives in any folder and pass the path to the constructor:\n&gt;&gt;&gt; ds = LIDC(root='/path/to/downloaded/data/folder/')\n&gt;&gt;&gt; print(len(ds.ids))\n# 1018\n&gt;&gt;&gt; print(ds.image(ds.ids[0]).shape)\n# (512, 512, 194)\n&gt;&gt;&gt; print(ds.cancer(ds.ids[0]).shape)\n# (512, 512, 194)\n</code></pre>"},{"location":"datasets-api/#amid.lidc.dataset.LIDC--references","title":"References","text":"<p>.. [1] Armato III, McLennan, et al. \"The lung image database consortium (lidc) and image database resource initiative (idri): a completed reference database of lung nodules on ct scans.\" Medical physics 38(2) (2011): 915\u2013931. https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3041807/</p>"},{"location":"datasets-api/#amid.lidc.dataset.LIDC.ids","title":"<code>ids()</code>","text":""},{"location":"datasets-api/#amid.lidc.dataset.LIDC.image","title":"<code>image(id: str)</code>","text":""},{"location":"datasets-api/#amid.lidc.dataset.LIDC.study_uid","title":"<code>study_uid(id: str)</code>","text":""},{"location":"datasets-api/#amid.lidc.dataset.LIDC.series_uid","title":"<code>series_uid(id: str)</code>","text":""},{"location":"datasets-api/#amid.lidc.dataset.LIDC.patient_id","title":"<code>patient_id(id: str)</code>","text":""},{"location":"datasets-api/#amid.lidc.dataset.LIDC.sop_uids","title":"<code>sop_uids(id: str)</code>","text":""},{"location":"datasets-api/#amid.lidc.dataset.LIDC.pixel_spacing","title":"<code>pixel_spacing(id: str)</code>","text":""},{"location":"datasets-api/#amid.lidc.dataset.LIDC.slice_locations","title":"<code>slice_locations(id: str)</code>","text":""},{"location":"datasets-api/#amid.lidc.dataset.LIDC.voxel_spacing","title":"<code>voxel_spacing(id: str)</code>","text":"<p>Returns voxel spacing along axes (x, y, z).</p>"},{"location":"datasets-api/#amid.lidc.dataset.LIDC.spacing","title":"<code>spacing(id: str)</code>","text":"<p>Volumetric spacing of the image. The maximum relative difference in <code>slice_locations</code> &lt; 1e-3 (except 4 images listed below), so we allow ourselves to use the common spacing for the whole 3D image.</p>"},{"location":"datasets-api/#amid.lidc.dataset.LIDC.spacing--note","title":"Note","text":"<p>The <code>slice_locations</code> attribute typically (but not always!) has the constant step. In LIDC dataset, only 4 images have difference in <code>slice_locations</code> &gt; 1e-3:     1.3.6.1.4.1.14519.5.2.1.6279.6001.526570782606728516388531252230     1.3.6.1.4.1.14519.5.2.1.6279.6001.329334252028672866365623335798     1.3.6.1.4.1.14519.5.2.1.6279.6001.245181799370098278918756923992     1.3.6.1.4.1.14519.5.2.1.6279.6001.103115201714075993579787468219 And these differences appear in the maximum of 3 slices. Therefore, we consider their impact negligible.</p>"},{"location":"datasets-api/#amid.lidc.dataset.LIDC.contrast_used","title":"<code>contrast_used(id: str)</code>","text":"<p>If the DICOM file for the scan had any Contrast tag, this is marked as <code>True</code>.</p>"},{"location":"datasets-api/#amid.lidc.dataset.LIDC.is_from_initial","title":"<code>is_from_initial(id: str)</code>","text":"<p>Indicates whether or not this PatientID was tagged as part of the initial 399 release.</p>"},{"location":"datasets-api/#amid.lidc.dataset.LIDC.orientation_matrix","title":"<code>orientation_matrix(id: str)</code>","text":""},{"location":"datasets-api/#amid.lidc.dataset.LIDC.sex","title":"<code>sex(id: str)</code>","text":""},{"location":"datasets-api/#amid.lidc.dataset.LIDC.age","title":"<code>age(id: str)</code>","text":""},{"location":"datasets-api/#amid.lidc.dataset.LIDC.conv_kernel","title":"<code>conv_kernel(id: str)</code>","text":""},{"location":"datasets-api/#amid.lidc.dataset.LIDC.kvp","title":"<code>kvp(id: str)</code>","text":""},{"location":"datasets-api/#amid.lidc.dataset.LIDC.study_date","title":"<code>study_date(id: str)</code>","text":""},{"location":"datasets-api/#amid.lidc.dataset.LIDC.accession_number","title":"<code>accession_number(id: str)</code>","text":""},{"location":"datasets-api/#amid.lidc.dataset.LIDC.nodules","title":"<code>nodules(id: str)</code>","text":""},{"location":"datasets-api/#amid.lidc.dataset.LIDC.nodules_masks","title":"<code>nodules_masks(id: str)</code>","text":""},{"location":"datasets-api/#amid.lidc.dataset.LIDC.cancer","title":"<code>cancer(id: str)</code>","text":""},{"location":"datasets-api/#amid.lits.dataset.LiTS","title":"<code>amid.lits.dataset.LiTS</code>","text":"<p>A (Li)ver (T)umor (S)egmentation dataset [1] from Medical Segmentation Decathlon [2]</p> <p>There are two segmentation tasks on this dataset: liver and liver tumor segmentation.</p> <p>Parameters:</p> Name Type Description Default <code>root</code> <code>(str, Path)</code> <p>path to the folder containing the raw downloaded archives. If not provided, the cache is assumed to be already populated.</p> required <code>version</code> <code>str</code> <p>the data version. Only has effect if the library was installed from a cloned git repository.</p> required"},{"location":"datasets-api/#amid.lits.dataset.LiTS--notes","title":"Notes","text":"<p>Follow the download instructions at https://competitions.codalab.org/competitions/17094.</p> <p>Then, the folder with raw downloaded data should contain two zip archives with the train data (<code>Training_Batch1.zip</code> and <code>Training_Batch2.zip</code>) and a folder with the test data (<code>LITS-Challenge-Test-Data</code>).</p> <p>The folder with test data should have original structure:     &lt;...&gt;/LITS-Challenge-Test-Data/test-volume-0.nii     &lt;...&gt;/LITS-Challenge-Test-Data/test-volume-1.nii     ...</p> <p>P.S. Organs boxes are also provided from a separate source https://github.com/superxuang/caffe_3d_faster_rcnn.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Place the downloaded archives in any folder and pass the path to the constructor:\n&gt;&gt;&gt; ds = LiTS(root='/path/to/downloaded/data/folder/')\n&gt;&gt;&gt; print(len(ds.ids))\n# 201\n&gt;&gt;&gt; print(ds.image(ds.ids[0]).shape)\n# (512, 512, 163)\n&gt;&gt;&gt; print(ds.tumor_mask(ds.ids[80]).shape)\n# (512, 512, 771)\n</code></pre>"},{"location":"datasets-api/#amid.lits.dataset.LiTS--references","title":"References","text":"<p>.. [1] Bilic, Patrick, et al. \"The liver tumor segmentation benchmark (lits).\"        arXiv preprint arXiv:1901.04056 (2019). .. [2] Antonelli, Michela, et al. \"The medical segmentation decathlon.\"        arXiv preprint arXiv:2106.05735 (2021).</p>"},{"location":"datasets-api/#amid.lits.dataset.LiTS.ids","title":"<code>ids()</code>","text":""},{"location":"datasets-api/#amid.lits.dataset.LiTS.fold","title":"<code>fold(id: str)</code>","text":""},{"location":"datasets-api/#amid.lits.dataset.LiTS.image","title":"<code>image(id: str)</code>","text":""},{"location":"datasets-api/#amid.lits.dataset.LiTS.affine","title":"<code>affine(id: str)</code>","text":"<p>The 4x4 matrix that gives the image's spatial orientation.</p>"},{"location":"datasets-api/#amid.lits.dataset.LiTS.voxel_spacing","title":"<code>voxel_spacing(id: str)</code>","text":""},{"location":"datasets-api/#amid.lits.dataset.LiTS.spacing","title":"<code>spacing(id: str)</code>","text":"<p>Returns voxel spacing along axes (x, y, z).</p>"},{"location":"datasets-api/#amid.lits.dataset.LiTS.mask","title":"<code>mask(id: str)</code>","text":""},{"location":"datasets-api/#amid.liver_medseg.LiverMedseg","title":"<code>amid.liver_medseg.LiverMedseg</code>","text":"<p>LiverMedseg is a public CT segmentation dataset with 50 annotated images. Case collection of 50 livers with their segments. Images obtained from Decathlon Medical Segmentation competition</p> <p>Parameters:</p> Name Type Description Default <code>root</code> <code>(str, Path)</code> <p>path to the folder containing the raw downloaded archives. If not provided, the cache is assumed to be already populated.</p> required <code>version</code> <code>str</code> <p>the data version. Only has effect if the library was installed from a cloned git repository.</p> required"},{"location":"datasets-api/#amid.liver_medseg.LiverMedseg--notes","title":"Notes","text":"<p>Download links: https://www.medseg.ai/database/liver-segments-50-cases</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Place the downloaded archives in any folder and pass the path to the constructor:\n&gt;&gt;&gt; ds = LiverMedseg(root='/path/to/archives/root')\n&gt;&gt;&gt; print(len(ds.ids))\n# 50\n&gt;&gt;&gt; print(ds.image(ds.ids[0]).shape)\n# (512, 512, 38)\n</code></pre>"},{"location":"datasets-api/#amid.liver_medseg.LiverMedseg--references","title":"References","text":""},{"location":"datasets-api/#amid.liver_medseg.LiverMedseg.ids","title":"<code>ids()</code>","text":""},{"location":"datasets-api/#amid.liver_medseg.LiverMedseg.image","title":"<code>image(id: str) -&gt; np.ndarray</code>","text":""},{"location":"datasets-api/#amid.liver_medseg.LiverMedseg.affine","title":"<code>affine(id: str) -&gt; np.ndarray</code>","text":"<p>The 4x4 matrix that gives the image's spatial orientation.</p>"},{"location":"datasets-api/#amid.liver_medseg.LiverMedseg.voxel_spacing","title":"<code>voxel_spacing(id: str) -&gt; tuple</code>","text":""},{"location":"datasets-api/#amid.liver_medseg.LiverMedseg.spacing","title":"<code>spacing(id: str) -&gt; tuple</code>","text":""},{"location":"datasets-api/#amid.liver_medseg.LiverMedseg.mask","title":"<code>mask(id: str) -&gt; np.ndarray</code>","text":""},{"location":"datasets-api/#amid.midrc.MIDRC","title":"<code>amid.midrc.MIDRC</code>","text":"<pre><code>MIDRC-RICORD dataset 1a is a public COVID-19 CT segmentation dataset with 120 scans.\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>root</code> <code>(str, Path)</code> <p>path to the folder containing the raw downloaded archives. If not provided, the cache is assumed to be already populated.</p> required <code>version</code> <code>str</code> <p>the data version. Only has effect if the library was installed from a cloned git repository.</p> required"},{"location":"datasets-api/#amid.midrc.MIDRC--notes","title":"Notes","text":"<p>Follow the download instructions at https://wiki.cancerimagingarchive.net/pages/viewpage.action?pageId=80969742 Download both Images and Annotations to the same folder</p> <p>Then, the folder with downloaded data should contain two paths with the data</p> <p>The folder should have this structure:     &lt;...&gt;//MIDRC-RICORD-1A     &lt;...&gt;//MIDRC-RICORD-1a_annotations_labelgroup_all_2020-Dec-8.json <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Place the downloaded archives in any folder and pass the path to the constructor:\n&gt;&gt;&gt; ds = MIDRC(root='/path/to/downloaded/data/folder/')\n&gt;&gt;&gt; print(len(ds.ids))\n 155\n&gt;&gt;&gt; print(ds.image(ds.ids[0]).shape)\n (512, 512, 112)\n&gt;&gt;&gt; print(ds.mask(ds.ids[80]).shape)\n (6, 512, 512, 450)\n</code></pre>"},{"location":"datasets-api/#amid.midrc.MIDRC--references","title":"References","text":""},{"location":"datasets-api/#amid.midrc.MIDRC.ids","title":"<code>ids()</code>","text":""},{"location":"datasets-api/#amid.midrc.MIDRC.image","title":"<code>image(id: str)</code>","text":""},{"location":"datasets-api/#amid.midrc.MIDRC.image_meta","title":"<code>image_meta(id: str)</code>","text":""},{"location":"datasets-api/#amid.midrc.MIDRC.spacing","title":"<code>spacing(id: str)</code>","text":""},{"location":"datasets-api/#amid.midrc.MIDRC.labels","title":"<code>labels(id: str)</code>","text":""},{"location":"datasets-api/#amid.midrc.MIDRC.mask","title":"<code>mask(id: str)</code>","text":""},{"location":"datasets-api/#amid.mood.MOOD","title":"<code>amid.mood.MOOD</code>","text":"<p>A (M)edival (O)ut-(O)f-(D)istribution analysis challenge [1]_</p> <p>This dataset contains raw brain MRI and abdominal CT images.</p> <p>Number of training samples: - Brain: 800 scans ( 256 x 256 x 256 ) - Abdominal: 550 scans ( 512 x 512 x 512 )</p> <p>For each setup there are 4 toy test samples with OOD cases.</p> <p>Parameters:</p> Name Type Description Default <code>root</code> <code>(str, Path)</code> <p>path to the folder containing the raw downloaded archives. If not provided, the cache is assumed to be already populated.</p> required <code>version</code> <code>str</code> <p>the data version. Only has effect if the library was installed from a cloned git repository.</p> required"},{"location":"datasets-api/#amid.mood.MOOD--notes","title":"Notes","text":"<p>Follow the download instructions at https://www.synapse.org/#!Synapse:syn21343101/wiki/599515.</p> <p>Then, the folder with raw downloaded data should contain four zip archives with data (<code>abdom_toy.zip</code>, <code>abdom_train.zip</code>, <code>brain_toy.zip</code> and <code>brain_train.zip</code>).</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Place the downloaded archives in any folder and pass the path to the constructor:\n&gt;&gt;&gt; ds = MOOD(root='/path/to/downloaded/data/folder/')\n&gt;&gt;&gt; print(len(ds.ids))\n# 1358\n&gt;&gt;&gt; print(ds.image(ds.ids[0]).shape)\n# (512, 512, 512)\n&gt;&gt;&gt; print(ds.pixel_label(ds.ids[0]).shape)\n# (512, 512, 512)\n</code></pre>"},{"location":"datasets-api/#amid.mood.MOOD--references","title":"References","text":"<p>.. [1] Zimmerer, Petersen, et al. \"Medical Out-of-Distribution Analysis Challenge 2022.\"        doi: 10.5281/zenodo.6362313 (2022).</p>"},{"location":"datasets-api/#amid.mood.MOOD.ids","title":"<code>ids()</code>","text":""},{"location":"datasets-api/#amid.mood.MOOD.fold","title":"<code>fold(id: str)</code>","text":"<p>Returns fold: train or toy (test).</p>"},{"location":"datasets-api/#amid.mood.MOOD.task","title":"<code>task(id: str)</code>","text":"<p>Returns task: brain (MRI) or abdominal (CT).</p>"},{"location":"datasets-api/#amid.mood.MOOD.image","title":"<code>image(id: str)</code>","text":""},{"location":"datasets-api/#amid.mood.MOOD.affine","title":"<code>affine(id: str)</code>","text":"<p>The 4x4 matrix that gives the image's spatial orientation.</p>"},{"location":"datasets-api/#amid.mood.MOOD.voxel_spacing","title":"<code>voxel_spacing(id: str)</code>","text":""},{"location":"datasets-api/#amid.mood.MOOD.spacing","title":"<code>spacing(id: str)</code>","text":"<p>Returns voxel spacing along axes (x, y, z).</p>"},{"location":"datasets-api/#amid.mood.MOOD.sample_label","title":"<code>sample_label(id: str)</code>","text":"<p>Returns sample-level OOD score for toy examples and None otherwise. 0 indicates no abnormality and 1 indicates abnormal input.</p>"},{"location":"datasets-api/#amid.mood.MOOD.pixel_label","title":"<code>pixel_label(id: str)</code>","text":"<p>Returns voxel-level OOD scores for toy examples and None otherwise. 0 indicates no abnormality and 1 indicates abnormal input.</p>"},{"location":"datasets-api/#amid.msd.MSD","title":"<code>amid.msd.MSD</code>","text":"<p>MSD is a Medical Segmentaton Decathlon Challenge with 10 tasks.</p> <p>Parameters:</p> Name Type Description Default <code>root</code> <code>(str, Path)</code> <p>path to the folder containing the raw downloaded archives. If not provided, the cache is assumed to be already populated.</p> required <code>version</code> <code>str</code> <p>the data version. Only has effect if the library was installed from a cloned git repository.</p> required"},{"location":"datasets-api/#amid.msd.MSD--notes","title":"Notes","text":"<p>Data can be downloaded here:http://medicaldecathlon.com/ or here: https://msd-for-monai.s3-us-west-2.amazonaws.com/ or here: https://drive.google.com/drive/folders/1HqEgzS8BV2c7xYNrZdEAnrHk7osJJ--2/ Then, the folder with raw downloaded data should contain tar archive with data and masks (<code>Task03_Liver.tar</code>).</p>"},{"location":"datasets-api/#amid.msd.MSD.ids","title":"<code>ids() -&gt; tuple</code>","text":""},{"location":"datasets-api/#amid.msd.MSD.train_test","title":"<code>train_test(id: str) -&gt; str</code>","text":""},{"location":"datasets-api/#amid.msd.MSD.task","title":"<code>task(id: str) -&gt; str</code>","text":""},{"location":"datasets-api/#amid.msd.MSD.image","title":"<code>image(id: str)</code>","text":""},{"location":"datasets-api/#amid.msd.MSD.affine","title":"<code>affine(id: str)</code>","text":"<p>The 4x4 matrix that gives the image's spatial orientation.</p>"},{"location":"datasets-api/#amid.msd.MSD.image_modality","title":"<code>image_modality(id: str) -&gt; str</code>","text":""},{"location":"datasets-api/#amid.msd.MSD.segmentation_labels","title":"<code>segmentation_labels(id: str) -&gt; dict</code>","text":"<p>Returns segmentation labels for the task</p>"},{"location":"datasets-api/#amid.msd.MSD.mask","title":"<code>mask(id: str)</code>","text":""},{"location":"datasets-api/#amid.medseg9.Medseg9","title":"<code>amid.medseg9.Medseg9</code>","text":"<p>Medseg9 is a public COVID-19 CT segmentation dataset with 9 annotated images.</p> <p>Parameters:</p> Name Type Description Default <code>root</code> <code>(str, Path)</code> <p>path to the folder containing the raw downloaded archives. If not provided, the cache is assumed to be already populated.</p> required <code>version</code> <code>str</code> <p>the data version. Only has effect if the library was installed from a cloned git repository.</p> required"},{"location":"datasets-api/#amid.medseg9.Medseg9--notes","title":"Notes","text":"<p>Data can be downloaded here: http://medicalsegmentation.com/covid19/.</p> <p>Then, the folder with raw downloaded data should contain three zip archives with data and masks (<code>rp_im.zip</code>, <code>rp_lung_msk.zip</code>, <code>rp_msk.zip</code>).</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Place the downloaded archives in any folder and pass the path to the constructor:\n&gt;&gt;&gt; ds = Medseg9(root='/path/to/downloaded/data/folder/')\n&gt;&gt;&gt; print(len(ds.ids))\n# 9\n&gt;&gt;&gt; print(ds.image(ds.ids[0]).shape)\n# (630, 630, 45)\n&gt;&gt;&gt; print(ds.covid(ds.ids[0]).shape)\n# (630, 630, 45)\n</code></pre>"},{"location":"datasets-api/#amid.medseg9.Medseg9.ids","title":"<code>ids()</code>","text":""},{"location":"datasets-api/#amid.medseg9.Medseg9.image","title":"<code>image(id: str)</code>","text":""},{"location":"datasets-api/#amid.medseg9.Medseg9.affine","title":"<code>affine(id: str)</code>","text":"<p>The 4x4 matrix that gives the image's spatial orientation.</p>"},{"location":"datasets-api/#amid.medseg9.Medseg9.voxel_spacing","title":"<code>voxel_spacing(id: str)</code>","text":""},{"location":"datasets-api/#amid.medseg9.Medseg9.spacing","title":"<code>spacing(id: str)</code>","text":"<p>Returns voxel spacing along axes (x, y, z).</p>"},{"location":"datasets-api/#amid.medseg9.Medseg9.lungs","title":"<code>lungs(id: str)</code>","text":""},{"location":"datasets-api/#amid.medseg9.Medseg9.covid","title":"<code>covid(id: str)</code>","text":"<p>int16 mask. 0 - normal, 1 - ground-glass opacities (\u043c\u0430\u0442\u043e\u0432\u043e\u0435 \u0441\u0442\u0435\u043a\u043b\u043e), 2 - consolidation (\u043a\u043e\u043d\u0441\u043e\u043b\u0438\u0434\u0430\u0446\u0438\u044f).</p>"},{"location":"datasets-api/#amid.cancer_500.dataset.MoscowCancer500","title":"<code>amid.cancer_500.dataset.MoscowCancer500</code>","text":"<p>The Moscow Radiology Cancer-500 dataset.</p> <p>Parameters:</p> Name Type Description Default <code>root</code> <code>(str, Path)</code> <p>path to the folder containing the raw downloaded files. If not provided, the cache is assumed to be already populated.</p> required <code>version</code> <code>str</code> <p>the data version. Only has effect if the library was installed from a cloned git repository.</p> required"},{"location":"datasets-api/#amid.cancer_500.dataset.MoscowCancer500--notes","title":"Notes","text":"<p>Download links: https://mosmed.ai/en/datasets/mosmeddata-kt-s-priznakami-raka-legkogo-tip-viii/ After pressing the <code>download</code> button you will have to provide an email address to which further instructions will be sent.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Place the downloaded files in any folder and pass the path to the constructor:\n&gt;&gt;&gt; ds = MoscowCancer500(root='/path/to/files/root')\n&gt;&gt;&gt; print(len(ds.ids))\n# 979\n&gt;&gt;&gt; print(ds.image(ds.ids[0]).shape)\n# (512, 512, 67)\n</code></pre>"},{"location":"datasets-api/#amid.cancer_500.dataset.MoscowCancer500.ids","title":"<code>ids()</code>","text":""},{"location":"datasets-api/#amid.cancer_500.dataset.MoscowCancer500.image","title":"<code>image(id: str)</code>","text":""},{"location":"datasets-api/#amid.cancer_500.dataset.MoscowCancer500.study_uid","title":"<code>study_uid(id: str)</code>","text":""},{"location":"datasets-api/#amid.cancer_500.dataset.MoscowCancer500.series_uid","title":"<code>series_uid(id: str)</code>","text":""},{"location":"datasets-api/#amid.cancer_500.dataset.MoscowCancer500.sop_uids","title":"<code>sop_uids(id: str)</code>","text":""},{"location":"datasets-api/#amid.cancer_500.dataset.MoscowCancer500.pixel_spacing","title":"<code>pixel_spacing(id: str)</code>","text":""},{"location":"datasets-api/#amid.cancer_500.dataset.MoscowCancer500.slice_locations","title":"<code>slice_locations(id: str)</code>","text":""},{"location":"datasets-api/#amid.cancer_500.dataset.MoscowCancer500.orientation_matrix","title":"<code>orientation_matrix(id: str)</code>","text":""},{"location":"datasets-api/#amid.cancer_500.dataset.MoscowCancer500.instance_numbers","title":"<code>instance_numbers(id: str)</code>","text":""},{"location":"datasets-api/#amid.cancer_500.dataset.MoscowCancer500.conv_kernel","title":"<code>conv_kernel(id: str)</code>","text":""},{"location":"datasets-api/#amid.cancer_500.dataset.MoscowCancer500.kvp","title":"<code>kvp(id: str)</code>","text":""},{"location":"datasets-api/#amid.cancer_500.dataset.MoscowCancer500.patient_id","title":"<code>patient_id(id: str)</code>","text":""},{"location":"datasets-api/#amid.cancer_500.dataset.MoscowCancer500.study_date","title":"<code>study_date(id: str)</code>","text":""},{"location":"datasets-api/#amid.cancer_500.dataset.MoscowCancer500.accession_number","title":"<code>accession_number(id: str)</code>","text":""},{"location":"datasets-api/#amid.cancer_500.dataset.MoscowCancer500.nodules","title":"<code>nodules(id: str)</code>","text":""},{"location":"datasets-api/#amid.covid_1110.MoscowCovid1110","title":"<code>amid.covid_1110.MoscowCovid1110</code>","text":"<p>The Moscow Radiology COVID-19 dataset.</p> <p>Parameters:</p> Name Type Description Default <code>root</code> <code>(str, Path)</code> <p>path to the folder containing the raw downloaded files. If not provided, the cache is assumed to be already populated.</p> required <code>version</code> <code>str</code> <p>the data version. Only has effect if the library was installed from a cloned git repository.</p> required"},{"location":"datasets-api/#amid.covid_1110.MoscowCovid1110--notes","title":"Notes","text":"<p>Download links: https://mosmed.ai/en/datasets/covid191110/</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Place the downloaded files in any folder and pass the path to the constructor:\n&gt;&gt;&gt; ds = MoscowCovid1110(root='/path/to/files/root')\n&gt;&gt;&gt; print(len(ds.ids))\n# 1110\n&gt;&gt;&gt; print(ds.image(ds.ids[0]).shape)\n# (512, 512, 43)\n</code></pre>"},{"location":"datasets-api/#amid.covid_1110.MoscowCovid1110.ids","title":"<code>ids()</code>","text":""},{"location":"datasets-api/#amid.covid_1110.MoscowCovid1110.image","title":"<code>image(id: str)</code>","text":""},{"location":"datasets-api/#amid.covid_1110.MoscowCovid1110.affine","title":"<code>affine(id: str)</code>","text":""},{"location":"datasets-api/#amid.covid_1110.MoscowCovid1110.label","title":"<code>label(id: str)</code>","text":""},{"location":"datasets-api/#amid.covid_1110.MoscowCovid1110.mask","title":"<code>mask(id: str)</code>","text":""},{"location":"datasets-api/#amid.nlst.NLST","title":"<code>amid.nlst.NLST</code>","text":"<pre><code>Dataset with low-dose CT scans of 26,254 patients acquired during National Lung Screening Trial.\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>root</code> <code>(str, Path)</code> <p>path to the folder (usually called NLST) containing the patient subfolders (like 101426). If not provided, the cache is assumed to be already populated.</p> required <code>version</code> <code>str</code> <p>the data version. Only has effect if the library was installed from a cloned git repository.</p> required"},{"location":"datasets-api/#amid.nlst.NLST--notes","title":"Notes","text":"<p>Follow the download instructions at https://wiki.cancerimagingarchive.net/display/NLST/National+Lung+Screening+Trial. The dicoms should be placed under the following folders' structure:     &lt;...&gt;//////*.dcm <p>Examples:</p> <pre><code>&gt;&gt;&gt; ds = NLST(root='/path/to/NLST/')\n&gt;&gt;&gt; print(len(ds.ids))\n ...\n&gt;&gt;&gt; print(ds.image(ds.ids[0]).shape)\n ...\n&gt;&gt;&gt; print(ds.mask(ds.ids[80]).shape)\n ...\n</code></pre>"},{"location":"datasets-api/#amid.nlst.NLST--references","title":"References","text":""},{"location":"datasets-api/#amid.nlst.NLST.ids","title":"<code>ids()</code>","text":""},{"location":"datasets-api/#amid.nlst.NLST.image","title":"<code>image(id: str)</code>","text":""},{"location":"datasets-api/#amid.nlst.NLST.study_uid","title":"<code>study_uid(id: str)</code>","text":""},{"location":"datasets-api/#amid.nlst.NLST.series_uid","title":"<code>series_uid(id: str)</code>","text":""},{"location":"datasets-api/#amid.nlst.NLST.sop_uids","title":"<code>sop_uids(id: str)</code>","text":""},{"location":"datasets-api/#amid.nlst.NLST.pixel_spacing","title":"<code>pixel_spacing(id: str)</code>","text":""},{"location":"datasets-api/#amid.nlst.NLST.slice_locations","title":"<code>slice_locations(id: str)</code>","text":""},{"location":"datasets-api/#amid.nlst.NLST.orientation_matrix","title":"<code>orientation_matrix(id: str)</code>","text":""},{"location":"datasets-api/#amid.nlst.NLST.conv_kernel","title":"<code>conv_kernel(id: str)</code>","text":""},{"location":"datasets-api/#amid.nlst.NLST.kvp","title":"<code>kvp(id: str)</code>","text":""},{"location":"datasets-api/#amid.nlst.NLST.patient_id","title":"<code>patient_id(id: str)</code>","text":""},{"location":"datasets-api/#amid.nlst.NLST.study_date","title":"<code>study_date(id: str)</code>","text":""},{"location":"datasets-api/#amid.nlst.NLST.accession_number","title":"<code>accession_number(id: str)</code>","text":""},{"location":"datasets-api/#amid.nsclc.NSCLC","title":"<code>amid.nsclc.NSCLC</code>","text":"<pre><code>NSCLC-Radiomics is a public cell lung cancer segmentation dataset with 422 patients.\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>root</code> <code>(str, Path)</code> <p>path to the folder containing the raw downloaded archives. If not provided, the cache is assumed to be already populated.</p> required <code>version</code> <code>str</code> <p>the data version. Only has effect if the library was installed from a cloned git repository.</p> required"},{"location":"datasets-api/#amid.nsclc.NSCLC--notes","title":"Notes","text":"<p>Follow the download instructions at https://wiki.cancerimagingarchive.net/display/Public/NSCLC-Radiomics</p> <p>The folder with downloaded data should contain two paths</p> <p>The folder should have this structure:     &lt;...&gt;//NSCLC-Radiomics/LUNG1-XXX <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Place the downloaded archives in any folder and pass the path to the constructor:\n&gt;&gt;&gt; ds = NSCLC(root='/path/to/downloaded/data/folder/')\n&gt;&gt;&gt; print(len(ds.ids))\n 422\n&gt;&gt;&gt; print(ds.image(ds.ids[0]).shape)\n (512, 512, 134)\n&gt;&gt;&gt; print(ds.mask(ds.ids[80]).shape)\n (512, 512, 108)\n</code></pre>"},{"location":"datasets-api/#amid.nsclc.NSCLC--references","title":"References","text":""},{"location":"datasets-api/#amid.nsclc.NSCLC.ids","title":"<code>ids()</code>","text":""},{"location":"datasets-api/#amid.nsclc.NSCLC.image","title":"<code>image(id: str)</code>","text":""},{"location":"datasets-api/#amid.nsclc.NSCLC.image_meta","title":"<code>image_meta(id: str)</code>","text":""},{"location":"datasets-api/#amid.nsclc.NSCLC.sex","title":"<code>sex(id: str) -&gt; str</code>","text":"<p>Sex of the patient.</p>"},{"location":"datasets-api/#amid.nsclc.NSCLC.age","title":"<code>age(id: str) -&gt; Union[int, None]</code>","text":"<p>Age of the patient, dataset contains 97 patients with unknown Age.</p>"},{"location":"datasets-api/#amid.nsclc.NSCLC.spacing","title":"<code>spacing(id: str)</code>","text":""},{"location":"datasets-api/#amid.nsclc.NSCLC.mask","title":"<code>mask(id: str)</code>","text":""},{"location":"datasets-api/#amid.nsclc.NSCLC.lung_left","title":"<code>lung_left(id: str)</code>","text":""},{"location":"datasets-api/#amid.nsclc.NSCLC.lung_right","title":"<code>lung_right(id: str)</code>","text":""},{"location":"datasets-api/#amid.nsclc.NSCLC.lungs_total","title":"<code>lungs_total(id: str)</code>","text":""},{"location":"datasets-api/#amid.nsclc.NSCLC.heart","title":"<code>heart(id: str)</code>","text":""},{"location":"datasets-api/#amid.nsclc.NSCLC.esophagus","title":"<code>esophagus(id: str)</code>","text":""},{"location":"datasets-api/#amid.nsclc.NSCLC.spinal_cord","title":"<code>spinal_cord(id: str)</code>","text":""},{"location":"datasets-api/#amid.rsna_bc.dataset.RSNABreastCancer","title":"<code>amid.rsna_bc.dataset.RSNABreastCancer</code>","text":""},{"location":"datasets-api/#amid.rsna_bc.dataset.RSNABreastCancer.site_id","title":"<code>site_id(id: str)</code>","text":""},{"location":"datasets-api/#amid.rsna_bc.dataset.RSNABreastCancer.patient_id","title":"<code>patient_id(id: str)</code>","text":""},{"location":"datasets-api/#amid.rsna_bc.dataset.RSNABreastCancer.image_id","title":"<code>image_id(id: str)</code>","text":""},{"location":"datasets-api/#amid.rsna_bc.dataset.RSNABreastCancer.laterality","title":"<code>laterality(id: str)</code>","text":""},{"location":"datasets-api/#amid.rsna_bc.dataset.RSNABreastCancer.view","title":"<code>view(id: str)</code>","text":""},{"location":"datasets-api/#amid.rsna_bc.dataset.RSNABreastCancer.age","title":"<code>age(id: str)</code>","text":""},{"location":"datasets-api/#amid.rsna_bc.dataset.RSNABreastCancer.cancer","title":"<code>cancer(id: str)</code>","text":""},{"location":"datasets-api/#amid.rsna_bc.dataset.RSNABreastCancer.biopsy","title":"<code>biopsy(id: str)</code>","text":""},{"location":"datasets-api/#amid.rsna_bc.dataset.RSNABreastCancer.invasive","title":"<code>invasive(id: str)</code>","text":""},{"location":"datasets-api/#amid.rsna_bc.dataset.RSNABreastCancer.BIRADS","title":"<code>BIRADS(id: str)</code>","text":""},{"location":"datasets-api/#amid.rsna_bc.dataset.RSNABreastCancer.implant","title":"<code>implant(id: str)</code>","text":""},{"location":"datasets-api/#amid.rsna_bc.dataset.RSNABreastCancer.density","title":"<code>density(id: str)</code>","text":""},{"location":"datasets-api/#amid.rsna_bc.dataset.RSNABreastCancer.machine_id","title":"<code>machine_id(id: str)</code>","text":""},{"location":"datasets-api/#amid.rsna_bc.dataset.RSNABreastCancer.prediction_id","title":"<code>prediction_id(id: str)</code>","text":""},{"location":"datasets-api/#amid.rsna_bc.dataset.RSNABreastCancer.difficult_negative_case","title":"<code>difficult_negative_case(id: str)</code>","text":""},{"location":"datasets-api/#amid.rsna_bc.dataset.RSNABreastCancer.ids","title":"<code>ids()</code>","text":""},{"location":"datasets-api/#amid.rsna_bc.dataset.RSNABreastCancer.image","title":"<code>image(id: str)</code>","text":""},{"location":"datasets-api/#amid.rsna_bc.dataset.RSNABreastCancer.padding_value","title":"<code>padding_value(id: str)</code>","text":""},{"location":"datasets-api/#amid.rsna_bc.dataset.RSNABreastCancer.intensity_sign","title":"<code>intensity_sign(id: str)</code>","text":""},{"location":"datasets-api/#amid.ribfrac.dataset.RibFrac","title":"<code>amid.ribfrac.dataset.RibFrac</code>","text":"<p>RibFrac dataset is a benchmark for developping algorithms on rib fracture detection, segmentation and classification. We hope this large-scale dataset could facilitate both clinical research for automatic rib fracture detection and diagnoses, and engineering research for 3D detection, segmentation and classification.</p> <p>Parameters:</p> Name Type Description Default <code>root</code> <code>(str, Path)</code> <p>path to the folder containing the raw downloaded archives. If not provided, the cache is assumed to be already populated.</p> required"},{"location":"datasets-api/#amid.ribfrac.dataset.RibFrac--notes","title":"Notes","text":"<p>Data downloaded from here: https://doi.org/10.5281/zenodo.3893507 -- train Part1 (300 images) https://doi.org/10.5281/zenodo.3893497 -- train Part2 (120 images) https://doi.org/10.5281/zenodo.3893495 -- val (80 images) https://zenodo.org/record/3993380 -- test (160 images without annotation)</p>"},{"location":"datasets-api/#amid.ribfrac.dataset.RibFrac--references","title":"References","text":"<p>Jiancheng Yang, Liang Jin, Bingbing Ni, &amp; Ming Li. (2020). RibFrac Dataset: A Benchmark for Rib Fracture Detection, Segmentation and Classification</p>"},{"location":"datasets-api/#amid.ribfrac.dataset.RibFrac.ids","title":"<code>ids()</code>","text":""},{"location":"datasets-api/#amid.ribfrac.dataset.RibFrac.image","title":"<code>image(id: str)</code>","text":""},{"location":"datasets-api/#amid.ribfrac.dataset.RibFrac.label","title":"<code>label(id: str)</code>","text":""},{"location":"datasets-api/#amid.ribfrac.dataset.RibFrac.affine","title":"<code>affine(id: str)</code>","text":"<p>The 4x4 matrix that gives the image's spatial orientation</p>"},{"location":"datasets-api/#amid.stanford_coca.StanfordCoCa","title":"<code>amid.stanford_coca.StanfordCoCa</code>","text":"<p>A Stanford AIMI's Co(ronary) Ca(lcium) dataset.</p> <p>Parameters:</p> Name Type Description Default <code>root</code> <code>(str, Path)</code> <p>path to the folder containing the raw downloaded archives. If not provided, the cache is assumed to be already populated.</p> required <code>version</code> <code>str</code> <p>the data version. Only has effect if the library was installed from a cloned git repository.</p> required"},{"location":"datasets-api/#amid.stanford_coca.StanfordCoCa--notes","title":"Notes","text":"<p>Follow the download instructions at https://stanfordaimi.azurewebsites.net/datasets/e8ca74dc-8dd4-4340-815a-60b41f6cb2aa. You'll need to register and accept the terms of use. After that, copy the files from Azure:</p> <p>azcopy copy 'some-generated-access-link' /path/to/downloaded/data/ --recursive=true</p> <p>Then, the folder with raw downloaded data should contain two subfolders - a subset with gated coronary CT scans and corresponding coronary calcium segmentation masks (<code>Gated_release_final</code>) and a folder with the non-gated CT scans with corresponding coronary with coronary artery calcium scores (<code>deidentified_nongated</code>).</p> <p>The folder with gated data should have original structure:     ./Gated_release_final/patient/0/folder-with-dcms/     ./Gated_release_final/calcium_xml/0.xml     ...</p> <p>The folder with nongated data should have original structure:     ./deidentified_nongated/0/folder-with-dcms/     ...</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Place the downloaded archives in any folder and pass the path to the constructor:\n&gt;&gt;&gt; ds = StanfordCoCa(root='/path/to/downloaded/data/folder/')\n&gt;&gt;&gt; print(len(ds.ids))\n# 971\n&gt;&gt;&gt; print(ds.image(ds.ids[0]).shape)\n# (512, 512, 57)\n</code></pre>"},{"location":"datasets-api/#amid.stanford_coca.StanfordCoCa.ids","title":"<code>ids()</code>","text":""},{"location":"datasets-api/#amid.stanford_coca.StanfordCoCa.image","title":"<code>image(id: str)</code>","text":""},{"location":"datasets-api/#amid.stanford_coca.StanfordCoCa.series_uid","title":"<code>series_uid(id: str)</code>","text":""},{"location":"datasets-api/#amid.stanford_coca.StanfordCoCa.study_uid","title":"<code>study_uid(id: str)</code>","text":""},{"location":"datasets-api/#amid.stanford_coca.StanfordCoCa.pixel_spacing","title":"<code>pixel_spacing(id: str)</code>","text":""},{"location":"datasets-api/#amid.stanford_coca.StanfordCoCa.slice_locations","title":"<code>slice_locations(id: str)</code>","text":""},{"location":"datasets-api/#amid.stanford_coca.StanfordCoCa.orientation_matrix","title":"<code>orientation_matrix(id: str)</code>","text":""},{"location":"datasets-api/#amid.stanford_coca.StanfordCoCa.calcifications","title":"<code>calcifications(id: str)</code>","text":"<p>Returns list of Calcifications</p>"},{"location":"datasets-api/#amid.stanford_coca.StanfordCoCa.score","title":"<code>score(id: str)</code>","text":""},{"location":"datasets-api/#amid.totalsegmentator.dataset.Totalsegmentator","title":"<code>amid.totalsegmentator.dataset.Totalsegmentator</code>","text":"<p>In 1204 CT images we segmented 104 anatomical structures (27 organs, 59 bones, 10 muscles, 8 vessels) covering a majority of relevant classes for most use cases.</p> <p>The CT images were randomly sampled from clinical routine, thus representing a real world dataset which generalizes to clinical application.</p> <p>The dataset contains a wide range of different pathologies, scanners, sequences and institutions. [1]</p> <p>Parameters:</p> Name Type Description Default <code>root</code> <code>(str, Path)</code> <p>absolute path to the downloaded archive. If not provided, the cache is assumed to be already populated.</p> required"},{"location":"datasets-api/#amid.totalsegmentator.dataset.Totalsegmentator--notes","title":"Notes","text":"<p>Download link: https://zenodo.org/record/6802614/files/Totalsegmentator_dataset.zip</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Download the archive to any folder and pass the path to the constructor:\n&gt;&gt;&gt; ds = Totalsegmentator(root='/path/to/the/downloaded/archive')\n&gt;&gt;&gt; print(len(ds.ids))\n# 1204\n&gt;&gt;&gt; print(ds.image(ds.ids[0]).shape)\n# (294, 192, 179)\n&gt;&gt;&gt; print(ds.aorta(ds.ids[25]).shape)\n# (320, 320, 145)\n</code></pre>"},{"location":"datasets-api/#amid.totalsegmentator.dataset.Totalsegmentator--references","title":"References","text":"<p>.. [1] Jakob Wasserthal (2022) Dataset with segmentations of 104 important anatomical structures in 1204 CT images. Available at: https://zenodo.org/record/6802614#.Y6M2MxXP1D8</p>"},{"location":"datasets-api/#amid.totalsegmentator.dataset.Totalsegmentator.ids","title":"<code>ids()</code>","text":""},{"location":"datasets-api/#amid.totalsegmentator.dataset.Totalsegmentator.image","title":"<code>image(id: str)</code>","text":""},{"location":"datasets-api/#amid.totalsegmentator.dataset.Totalsegmentator.affine","title":"<code>affine(id: str)</code>","text":"<p>The 4x4 matrix that gives the image's spatial orientation</p>"},{"location":"datasets-api/#amid.upenn_gbm.upenn_gbm.UPENN_GBM","title":"<code>amid.upenn_gbm.upenn_gbm.UPENN_GBM</code>","text":"<p>Multi-parametric magnetic resonance imaging (mpMRI) scans for de novo Glioblastoma   (GBM) patients from the University of Pennsylvania Health System (UPENN-GBM). Dataset contains 630 patients.</p> <p>All samples are registered to a common atlas (SRI)     using a uniform preprocessing and the segmentation are aligned with them.</p> <p>Parameters:</p> Name Type Description Default <code>root</code> <code>(str, Path)</code> <p>path to the folder containing the raw downloaded archives. If not provided, the cache is assumed to be already populated.</p> required"},{"location":"datasets-api/#amid.upenn_gbm.upenn_gbm.UPENN_GBM--notes","title":"Notes","text":"<p>Follow the download instructions at https://wiki.cancerimagingarchive.net/pages/viewpage.action?pageId=70225642 Download to the root folder nifti images and metadata. Organise folder as folows:</p> <p>&lt;...&gt;//NIfTI-files/images_segm/UPENN-GBM-00054_11_segm.nii.gz &lt;...&gt;//NIfTI-files/... <p>&lt;...&gt;//UPENN-GBM_clinical_info_v1.0.csv &lt;...&gt;//UPENN-GBM_acquisition.csv <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Place the downloaded archives in any folder and pass the path to the constructor:\n&gt;&gt;&gt; ds = UPENN_GBM(root='/path/to/downloaded/data/folder/')\n&gt;&gt;&gt; print(len(ds.ids))\n# 671\n&gt;&gt;&gt; print(ds.image(ds.ids[215]).shape)\n# (4, 240, 240, 155)\n&gt;&gt;&gt; print(d.acqusition_info(d.ids[215]).manufacturer)\n# SIEMENS\n</code></pre>"},{"location":"datasets-api/#amid.upenn_gbm.upenn_gbm.UPENN_GBM--references","title":"References","text":"<p>.. [1] Bakas, S., Sako, C., Akbari, H., Bilello, M., Sotiras, A., Shukla, G., Rudie,   J. D., Flores Santamaria, N., Fathi Kazerooni, A., Pati, S., Rathore, S., Mamourian, E., Ha, S. M., Parker, W., Doshi, J., Baid, U., Bergman, M., Binder, Z. A., Verma, R., \u2026 Davatzikos, C. (2021). Multi-parametric magnetic resonance imaging (mpMRI) scans for de novo Glioblastoma (GBM) patients from the University of Pennsylvania Health System (UPENN-GBM) (Version 2) [Data set]. The Cancer Imaging Archive. https://doi.org/10.7937/TCIA.709X-DN49</p>"},{"location":"datasets-api/#amid.upenn_gbm.upenn_gbm.UPENN_GBM.ids","title":"<code>ids()</code>","text":""},{"location":"datasets-api/#amid.upenn_gbm.upenn_gbm.UPENN_GBM.modalities","title":"<code>modalities(id: str)</code>","text":""},{"location":"datasets-api/#amid.upenn_gbm.upenn_gbm.UPENN_GBM.dsc_modalities","title":"<code>dsc_modalities(id: str)</code>","text":""},{"location":"datasets-api/#amid.upenn_gbm.upenn_gbm.UPENN_GBM.dti_modalities","title":"<code>dti_modalities(id: str)</code>","text":""},{"location":"datasets-api/#amid.upenn_gbm.upenn_gbm.UPENN_GBM.mask","title":"<code>mask(id: str)</code>","text":""},{"location":"datasets-api/#amid.upenn_gbm.upenn_gbm.UPENN_GBM.is_mask_automated","title":"<code>is_mask_automated(id: str)</code>","text":""},{"location":"datasets-api/#amid.upenn_gbm.upenn_gbm.UPENN_GBM.image","title":"<code>image(id: str)</code>","text":""},{"location":"datasets-api/#amid.upenn_gbm.upenn_gbm.UPENN_GBM.image_unstripped","title":"<code>image_unstripped(id: str)</code>","text":""},{"location":"datasets-api/#amid.upenn_gbm.upenn_gbm.UPENN_GBM.image_DTI","title":"<code>image_DTI(id: str)</code>","text":""},{"location":"datasets-api/#amid.upenn_gbm.upenn_gbm.UPENN_GBM.image_DSC","title":"<code>image_DSC(id: str)</code>","text":""},{"location":"datasets-api/#amid.upenn_gbm.upenn_gbm.UPENN_GBM.clinical_info","title":"<code>clinical_info(id: str) -&gt; ClinicalInfo</code>","text":""},{"location":"datasets-api/#amid.upenn_gbm.upenn_gbm.UPENN_GBM.acqusition_info","title":"<code>acqusition_info(id: str) -&gt; AcquisitionInfo</code>","text":""},{"location":"datasets-api/#amid.upenn_gbm.upenn_gbm.UPENN_GBM.subject_id","title":"<code>subject_id(id: str)</code>","text":""},{"location":"datasets-api/#amid.upenn_gbm.upenn_gbm.UPENN_GBM.affine","title":"<code>affine(id: str)</code>","text":""},{"location":"datasets-api/#amid.upenn_gbm.upenn_gbm.UPENN_GBM.spacing","title":"<code>spacing(id: str)</code>","text":""},{"location":"datasets-api/#amid.vs_seg.dataset.VSSEG","title":"<code>amid.vs_seg.dataset.VSSEG</code>","text":"<p>Segmentation of vestibular schwannoma from MRI, an open annotated dataset ... (VS-SEG) [1]_.</p> <p>The dataset contains 250 pairs of T1c and T2 images of the brain with the vestibular schwannoma segmentation task.</p> <p>Parameters:</p> Name Type Description Default <code>root</code> <code>(str, Path)</code> <p>path to the folder containing the raw downloaded archives. If not provided, the cache is assumed to be already populated.</p> required <code>version</code> <code>str</code> <p>the data version. Only has effect if the library was installed from a cloned git repository.</p> required"},{"location":"datasets-api/#amid.vs_seg.dataset.VSSEG--notes","title":"Notes","text":"<p>The dataset and corresponding metadata could be downloaded at the TCIA page: https://wiki.cancerimagingarchive.net/pages/viewpage.action?pageId=70229053.</p> <p>To download DICOM images using <code>.tcia</code> file, we used public build of TCIA downloader: https://github.com/ygidtu/NBIA_data_retriever_CLI.</p> <p>Then, download the rest of metadata from TCIA page:   - <code>DirectoryNamesMappingModality.csv</code>   - <code>Vestibular-Schwannoma-SEG_matrices Mar 2021.zip</code>   - <code>Vestibular-Schwannoma-SEG contours Mar 2021.zip</code></p> <p>and unzip the latter two <code>.zip</code> archives.</p> <p>So the <code>root</code> folder should contain 3 folders and 1 <code>.csv</code> file:     &lt;...&gt;/DirectoryNamesMappingModality.csv     &lt;...&gt;/Vestibular-Schwannoma-SEG/             \u251c\u2500\u2500 VS-SEG-001/...             \u251c\u2500\u2500 VS-SEG-002/...             \u2514\u2500\u2500 ...     &lt;...&gt;/contours/     &lt;...&gt;/registration_matrices/</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Place the downloaded archives in any folder and pass the path to the constructor:\n&gt;&gt;&gt; ds = VSSEG(root='/path/to/downloaded/data/folder/')\n&gt;&gt;&gt; print(len(ds.ids))\n# 484\n&gt;&gt;&gt; print(ds.image(ds.ids[0]).shape)\n# (512, 512, 120)\n&gt;&gt;&gt; print(ds.schwannoma(ds.ids[1]).shape)\n# (384, 384, 80)\n</code></pre>"},{"location":"datasets-api/#amid.vs_seg.dataset.VSSEG--references","title":"References","text":"<p>.. [1] Shapey, Jonathan, et al. \"Segmentation of vestibular schwannoma from MRI,        an open annotated dataset and baseline algorithm.\"        Scientific Data 8.1 (2021): 1-6.        https://www.nature.com/articles/s41597-021-01064-w</p>"},{"location":"datasets-api/#amid.vs_seg.dataset.VSSEG.ids","title":"<code>ids()</code>","text":""},{"location":"datasets-api/#amid.vs_seg.dataset.VSSEG.modality","title":"<code>modality(id: str)</code>","text":""},{"location":"datasets-api/#amid.vs_seg.dataset.VSSEG.subject_id","title":"<code>subject_id(id: str)</code>","text":""},{"location":"datasets-api/#amid.vs_seg.dataset.VSSEG.image","title":"<code>image(id: str)</code>","text":""},{"location":"datasets-api/#amid.vs_seg.dataset.VSSEG.spacing","title":"<code>spacing(id: str)</code>","text":"<p>The maximum relative difference in <code>slice_locations</code> &lt; 1e-12, so we allow ourselves to use the common spacing for the whole 3D image.</p>"},{"location":"datasets-api/#amid.vs_seg.dataset.VSSEG.schwannoma","title":"<code>schwannoma(id: str)</code>","text":""},{"location":"datasets-api/#amid.vs_seg.dataset.VSSEG.cochlea","title":"<code>cochlea(id: str)</code>","text":""},{"location":"datasets-api/#amid.vs_seg.dataset.VSSEG.meningioma","title":"<code>meningioma(id: str)</code>","text":""},{"location":"datasets-api/#amid.vs_seg.dataset.VSSEG.study_uid","title":"<code>study_uid(id: str)</code>","text":""},{"location":"datasets-api/#amid.vs_seg.dataset.VSSEG.series_uid","title":"<code>series_uid(id: str)</code>","text":""},{"location":"datasets-api/#amid.vs_seg.dataset.VSSEG.patient_id","title":"<code>patient_id(id: str)</code>","text":""},{"location":"datasets-api/#amid.vs_seg.dataset.VSSEG.study_date","title":"<code>study_date(id: str)</code>","text":""},{"location":"datasets-api/#amid.verse.VerSe","title":"<code>amid.verse.VerSe</code>","text":"<p>A Vertebral Segmentation Dataset with Fracture Grading [1]_</p> <p>The dataset was used in the MICCAI-2019 and MICCAI-2020 Vertebrae Segmentation Challenges.</p> <p>Parameters:</p> Name Type Description Default <code>root</code> <code>(str, Path)</code> <p>path to the folder containing the raw downloaded archives. If not provided, the cache is assumed to be already populated.</p> required <code>version</code> <code>str</code> <p>the data version. Only has effect if the library was installed from a cloned git repository.</p> required"},{"location":"datasets-api/#amid.verse.VerSe--notes","title":"Notes","text":"<p>Download links:     2019: https://osf.io/jtfa5/     2020: https://osf.io/4skx2/</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Place the downloaded archives in any folder and pass the path to the constructor:\n&gt;&gt;&gt; ds = VerSe(root='/path/to/archives/root')\n&gt;&gt;&gt; print(len(ds.ids))\n# 374\n&gt;&gt;&gt; print(ds.image(ds.ids[0]).shape)\n# (512, 512, 214)\n</code></pre>"},{"location":"datasets-api/#amid.verse.VerSe--references","title":"References","text":"<p>.. [1] L\u00f6ffler MT, Sekuboyina A, Jacob A, et al. A Vertebral Segmentation Dataset with Fracture Grading.    Radiol Artif Intell. 2020;2(4):e190138. Published 2020 Jul 29. doi:10.1148/ryai.2020190138</p>"},{"location":"datasets-api/#amid.verse.VerSe.ids","title":"<code>ids()</code>","text":""},{"location":"datasets-api/#amid.verse.VerSe.image","title":"<code>image(id: str)</code>","text":""},{"location":"datasets-api/#amid.verse.VerSe.affine","title":"<code>affine(id: str)</code>","text":"<p>The 4x4 matrix that gives the image's spatial orientation</p>"},{"location":"datasets-api/#amid.verse.VerSe.split","title":"<code>split(id: str)</code>","text":"<p>The split in which this entry is contained: training, validate, test</p>"},{"location":"datasets-api/#amid.verse.VerSe.patient","title":"<code>patient(id: str)</code>","text":"<p>The unique patient id</p>"},{"location":"datasets-api/#amid.verse.VerSe.year","title":"<code>year(id: str)</code>","text":"<p>The year in which this entry was published: 2019, 2020</p>"},{"location":"datasets-api/#amid.verse.VerSe.centers","title":"<code>centers(id: str)</code>","text":"<p>Vertebrae centers in format {label: [x, y, z]}</p>"},{"location":"datasets-api/#amid.verse.VerSe.masks","title":"<code>masks(id: str) -&gt; Union[np.ndarray, None]</code>","text":"<p>Vertebrae masks</p>"},{"location":"datasets/","title":"Datasets","text":"Name Entries Body region License Modality Prep data size Raw data size Task Link AMOS 600 Abdomen CC BY 4.0 CT, MRI 89,5G 23G Supervised multi-modality abdominal multi-organ segmentation Source BIMCVCovid19 16335 Chest CC BY 4.0 CT 859G 859G Segmentation Source BraTS2021 5880 Head CC BY-NC-SA 4.0 MRI T1, MRI T1Gd, MRI T2, MRI T2-FLAIR 8,96G 15G Segmentation, Classification, Domain Adaptation Source CC359 359 Head CC BY-ND 4.0 MRI T1 14,66G 4,1G Segmentation Source CLDetection2023 400 Head CC BY-NC 4.0 X-ray 1.8G 1.5G Keypoint detection Source CRLM 197 Abdomen CC BY 4.0 CT, SEG 11G 11G Segmentation, Classification Source CT_ICH 75 Head PhysioNet Restricted Health Data License 1.5.0 CT 661M 2,8G Intracranial hemorrhage segmentation Source CrossMoDA 484 Head CC BY-NC-SA 4.0 MRI T1c, MRI T2hr 8,96G 17G Segmentation, Classification, Domain Adaptation Source DeepLesion 20094 Abdomen, Thorax DeepLesion data license CT 259G 259G Localisation, Detection, Classification Source EGD 3096 Head EGD data license FLAIR, MRI T1, MRI T1GD, MRI T2 107,49G 40G Segmentation Source FLARE2022 2100 Abdomen CT 347G 247G Semi-supervised abdominal organ segmentation Source LIDC 1018 Chest CC BY 3.0 CT 71,2G 126G Lung nodules segmentation Source LiTS 201 Abdominal CC BY-NC-ND 4.0 CT 24,7G 35G Segmentation Source LiverMedseg 50 Chest, Abdomen CC BY-SA 4.0 CT 1,88G 616M Segmentation Source MIDRC 155 Thorax CC BY-NC 4.0 CT 7,9G 12G COVID-19 Segmentation Source MOOD 1358 Head, Abdominal MRI, CT 405G 120G Out-of-distribution detection Source MSD 2628 Chest, Abdominal, Head CC BY-SA 4.0 CT, CE CT, MRI, MRI FLAIR, MRI T1w, MRI t1gd, MRI T2w, MRI T2, MRI ADC 97.8G Image segmentation Source Medseg9 9 Chest CC0 1.0 CT 300M 310M COVID-19 segmentation Source MoscowCancer500 979 Thorax CT 103G 187G Lung Cancer Detection Source MoscowCovid1110 1110 Thorax CT 21G COVID-19 Segmentation Source NLST 13624 Thorax CC BY 3.0 CT Source NSCLC 422 Thorax CC BY 3.0 CT 13G 34G Tumor Segmentation Source RSNABreastCancer 54710 Thorax Non-Commercial Use MG 294G 271G Breast cancer classification Source RibFrac 660 Chest CC BY-NC 4.0 CT 77.8 G Segmentation Source StanfordCoCa 971 Coronary, Chest Stanford University Dataset Research Use Agreement CT 28G Coronary Calcium Segmentation Source Totalsegmentator 1204 Head, Thorax, Abdomen, Pelvis, Legs CC BY 4.0 CT 35G 35G Supervised anatomical structures segmentation Source UPENN_GBM 671 Head CC BY 4.0 FLAIR, MRI T1, MRI T1GD, MRI T2, DSC MRI, DTI MRI 70G 69G Segmentation Source VSSEG 484 Head CC BY 4.0 MRI T1c, MRI T2 14,42G 27G Segmentation Source VerSe 374 Thorax, Abdomen CC BY-SA 4.0 CT 97G Vertebrae Segmentation Source"},{"location":"recipes/RSNABreastCancer/","title":"RSNABreastCancer","text":"In\u00a0[\u00a0]: Copied! <pre>from connectome import Transform\n\n\nclass Normalize(Transform):\n    __inherit__ = True\n\n    def image(image, padding_value, intensity_sign):\n        if padding_value is not None:\n            if padding_value &gt; 0:\n                return padding_value - image\n            return image\n\n        if intensity_sign == 1:\n            return image.max() - image\n\n        return image\n</pre> from connectome import Transform   class Normalize(Transform):     __inherit__ = True      def image(image, padding_value, intensity_sign):         if padding_value is not None:             if padding_value &gt; 0:                 return padding_value - image             return image          if intensity_sign == 1:             return image.max() - image          return image In\u00a0[\u00a0]: Copied! <pre>from connectome import Apply\nfrom scipy.ndimage import zoom\n\n# 0.25 - is the downsample factor. It should probably be tuned via cross-validation\nZoom = Apply(image=lambda x: zoom(np.float32(x), 0.25, order=1))\n</pre> from connectome import Apply from scipy.ndimage import zoom  # 0.25 - is the downsample factor. It should probably be tuned via cross-validation Zoom = Apply(image=lambda x: zoom(np.float32(x), 0.25, order=1)) In\u00a0[\u00a0]: Copied! <pre>from connectome import Transform\nfrom skimage.morphology import label\n\n\nclass GreatestComponent(Transform):\n    __inherit__ = True\n\n    def image(image):\n        lbl = label(image &gt; 0)\n        values, counts = np.unique(lbl, return_counts=True)\n        foreground = values != 0\n        component = values[foreground][counts[foreground].argmax()]\n        # select all the components greater than the background\n        #  + the greatest foreground component\n        components = set(values[counts &gt; counts[~foreground]]) | {component}\n        if len(components) &gt; 1:\n            # if there are several components - pick the one with the greatest intensity\n            component = max(components, key=lambda c: image[lbl == c].mean())\n\n        return image * (lbl == component)\n\n\nclass CropBackground(Transform):\n    __inherit__ = True\n\n    def image(image):\n        mask = image &gt; 0\n        xs, = mask.any(0).nonzero()\n        ys, = mask.any(1).nonzero()\n        return image[ys.min():ys.max() + 1, xs.min():xs.max() + 1]\n</pre> from connectome import Transform from skimage.morphology import label   class GreatestComponent(Transform):     __inherit__ = True      def image(image):         lbl = label(image &gt; 0)         values, counts = np.unique(lbl, return_counts=True)         foreground = values != 0         component = values[foreground][counts[foreground].argmax()]         # select all the components greater than the background         #  + the greatest foreground component         components = set(values[counts &gt; counts[~foreground]]) | {component}         if len(components) &gt; 1:             # if there are several components - pick the one with the greatest intensity             component = max(components, key=lambda c: image[lbl == c].mean())          return image * (lbl == component)   class CropBackground(Transform):     __inherit__ = True      def image(image):         mask = image &gt; 0         xs, = mask.any(0).nonzero()         ys, = mask.any(1).nonzero()         return image[ys.min():ys.max() + 1, xs.min():xs.max() + 1] In\u00a0[\u00a0]: Copied! <pre>from connectome import Transform, impure\nimport numpy as np\n\n\nclass RandomFlip(Transform):\n    __inherit__ = True\n\n    @impure\n    def _flip():\n        return np.random.binomial(1, 0.5)\n\n    def image(image, _flip):\n        if _flip:\n            return np.flip(image, axis=1)\n        return image\n</pre> from connectome import Transform, impure import numpy as np   class RandomFlip(Transform):     __inherit__ = True      @impure     def _flip():         return np.random.binomial(1, 0.5)      def image(image, _flip):         if _flip:             return np.flip(image, axis=1)         return image In\u00a0[\u00a0]: Copied! <pre>from amid.rsna_bc import RSNABreastCancer\nfrom connectome import Chain\n\nds = Chain(\n    RSNABreastCancer('/path/to/downloaded/folder'),\n    Normalize(),\n    Apply(image=lambda x: zoom(np.float32(x), 0.25, order=1)),\n    GreatestComponent(),\n    CropBackground(),\n\n    # aug\n    RandomFlip(),\n)\n</pre> from amid.rsna_bc import RSNABreastCancer from connectome import Chain  ds = Chain(     RSNABreastCancer('/path/to/downloaded/folder'),     Normalize(),     Apply(image=lambda x: zoom(np.float32(x), 0.25, order=1)),     GreatestComponent(),     CropBackground(),      # aug     RandomFlip(), )"},{"location":"recipes/RSNABreastCancer/#normalization","title":"Normalization\u00b6","text":""},{"location":"recipes/RSNABreastCancer/#zoom-to-reduce-image-size","title":"Zoom to reduce image size\u00b6","text":""},{"location":"recipes/RSNABreastCancer/#artifacts-and-background-removal","title":"Artifacts and background removal\u00b6","text":""},{"location":"recipes/RSNABreastCancer/#data-augmentation","title":"Data augmentation\u00b6","text":""},{"location":"recipes/RSNABreastCancer/#combining-it-all-together","title":"Combining it all together\u00b6","text":""}]}